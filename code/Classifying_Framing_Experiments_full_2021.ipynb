{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn\n",
    "#%pip install torch\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from collections import namedtuple\n",
    "from math import sqrt\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.base import clone\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\" \n",
    "DATA_NPZ = DATA_DIR + \"data2021.npz\"\n",
    "RESULTS_FILE = DATA_DIR + 'results2021full.tsv'\n",
    "OUTPUT_FILE = DATA_DIR + 'output2021full.npz'\n",
    "\n",
    "## load files\n",
    "data = np.load(DATA_NPZ)\n",
    "\n",
    "X_2D_transcriptions = data['X_2D_transcriptions']\n",
    "X_2D_descriptions = data['X_2D_descriptions']\n",
    "X_2D_titles = data['X_2D_title']\n",
    "\n",
    "X_2D = np.hstack([X_2D_titles, X_2D_descriptions, X_2D_transcriptions])\n",
    "\n",
    "y_crowd = data['y_crowd']\n",
    "y_experts = data['y_experts']\n",
    "y_combined = data['y_combined']\n",
    "\n",
    "# retrieve indices of labeled samples\n",
    "experts_pilot_idx = np.where(y_experts > -1)[0]  # equal pilot subset\n",
    "\n",
    "crowd_pilot_idx = np.array([idx for idx in experts_pilot_idx if y_crowd[idx] > -1])\n",
    "crowd_all_idx = np.where(y_crowd > -1)[0]\n",
    "\n",
    "# note: combined on pilot idx is same as experts on pilot idx since the experts labels are used for this part\n",
    "combined_all_idx = np.where(y_combined > -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3684733569\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    return seed\n",
    "    \n",
    "print(set_seed())  # make reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "outputs = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the expert labels are part of the combined sets and that we also compute the performance on the expert labels. This means that we are partially learning on the same samples are that we test on, which gives a better performance but which shouldn't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(y, test_ratio=.5):\n",
    "    train_idx = list()\n",
    "    test_idx = list()\n",
    "    \n",
    "    strats = [np.where(y == lab)[0] for lab in np.unique(y) if lab > -1]\n",
    "    for strat in strats:\n",
    "        n = strat.shape[0]\n",
    "        train_idx.append(strat[:int(n*(1-test_ratio))])\n",
    "        test_idx.append(strat[int(n*(1-test_ratio)):])\n",
    "        \n",
    "    train_idx = np.concatenate(train_idx)\n",
    "    test_idx = np.concatenate(test_idx)\n",
    "    \n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(test_idx)\n",
    "    \n",
    "    return (train_idx, test_idx)\n",
    "\n",
    "def create_splits_one_hot(y):\n",
    "    vec = -np.ones(y.shape[0])\n",
    "    nonzero = y.nonzero()\n",
    "    vec[nonzero[:,0]] = nonzero[:,1].float()\n",
    "    \n",
    "    return create_splits(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def ridge_classifier(X, y, index):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = X.shape[0]   \n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    for fold_i in range(N_FOLDS):\n",
    "        train_split, test_split = create_splits(y, 0.2)\n",
    "        \n",
    "        model = RidgeClassifier().fit(X[train_split], y[train_split])\n",
    "        y_hat = model.predict(X[test_split])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[test_split], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, index[test_split]] = y_hat\n",
    "        \n",
    "    return (scores, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert ===\n",
      "=== Results on crowd pilot ===\n",
      "=== Results on crowd all ===\n",
      "=== Results on combined all ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results on expert ===\")\n",
    "ridge_acc_experts_pilot, ridge_out_experts_pilot = ridge_classifier(X_2D, y_experts, experts_pilot_idx)\n",
    "results['ridge_experts_pilot'] = ridge_acc_experts_pilot\n",
    "outputs.append(ridge_out_experts_pilot)\n",
    "\n",
    "print(\"=== Results on crowd pilot ===\")\n",
    "ridge_acc_crowd_pilot, ridge_out_crowd_pilot = ridge_classifier(X_2D, y_crowd, crowd_pilot_idx)\n",
    "results['ridge_crowd_pilot'] = ridge_acc_crowd_pilot\n",
    "outputs.append(ridge_out_crowd_pilot)\n",
    "\n",
    "print(\"=== Results on crowd all ===\")\n",
    "ridge_acc_crowd_all, ridge_out_crowd_all = ridge_classifier(X_2D, y_crowd, crowd_all_idx)\n",
    "results['ridge_crowd_all'] = ridge_acc_crowd_all\n",
    "outputs.append(ridge_out_crowd_all)\n",
    "\n",
    "print(\"=== Results on combined all ===\")\n",
    "ridge_acc_combined_all, ridge_out_combined_all = ridge_classifier(X_2D, y_combined, combined_all_idx)\n",
    "results['ridge_combined_all'] = ridge_acc_combined_all\n",
    "outputs.append(ridge_out_combined_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def naive_bayes_classifier(X, y, index):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = X.shape[0]   \n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    for fold_i in range(N_FOLDS):\n",
    "        train_split, test_split = create_splits(y, 0.2)\n",
    "        \n",
    "        model = GaussianNB().fit(X[train_split], y[train_split])\n",
    "        y_hat = model.predict(X[test_split])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[test_split], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, index[test_split]] = y_hat\n",
    "        \n",
    "    return (scores, output)\n",
    "\n",
    "def naive_bayes_classifier_incremental(X, y, idx_experts, idx_crowd):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = y.shape[0]   \n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    for fold_i in range(N_FOLDS):\n",
    "        idx_crowd_unique = np.setdiff1d(idx_crowd, idx_experts)\n",
    "        crowd_num_samples = idx_crowd_unique.shape[0]\n",
    "        experts_num_samples = idx_experts.shape[0]\n",
    "        \n",
    "        experts_train_split = np.random.choice(idx_experts,\n",
    "                                               int(experts_num_samples*.8),\n",
    "                                               replace=False)\n",
    "        experts_test_split = np.setdiff1d(idx_experts, experts_train_split)\n",
    "\n",
    "        crowd_train_split = np.random.choice(idx_crowd_unique,\n",
    "                                             int(crowd_num_samples*.8),\n",
    "                                             replace=False)\n",
    "        crowd_test_split = np.setdiff1d(idx_crowd_unique, crowd_train_split)\n",
    "        \n",
    "        idx_test = np.union1d(experts_test_split, crowd_test_split)\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            model = GaussianNB().partial_fit(X[experts_train_split], y[experts_train_split], np.unique(y_combined[idx_experts]))\n",
    "            for i in crowd_train_split:\n",
    "                model.partial_fit([X[i]], [y[i]])\n",
    "            \n",
    "            y_hat = model.predict(X[idx_test])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[idx_test], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, idx_test] = y_hat\n",
    "        \n",
    "    return (scores, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert pilot ===\n",
      "=== Results on crowd pilot ===\n",
      "=== Results on crowd all ===\n",
      "=== Results on combined all ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results on expert pilot ===\")\n",
    "bayes_acc_experts_pilot, bayes_out_experts_pilot = naive_bayes_classifier(X_2D, y_experts, experts_pilot_idx)\n",
    "results['bayes_experts_pilot'] = bayes_acc_experts_pilot\n",
    "outputs.append(bayes_out_experts_pilot)\n",
    "\n",
    "print(\"=== Results on crowd pilot ===\")\n",
    "bayes_acc_crowd_pilot, bayes_out_crowd_pilot = naive_bayes_classifier(X_2D, y_crowd, crowd_pilot_idx)\n",
    "results['bayes_crowd_pilot'] = bayes_acc_crowd_pilot\n",
    "outputs.append(bayes_out_crowd_pilot)\n",
    "\n",
    "print(\"=== Results on crowd all ===\")\n",
    "bayes_acc_crowd_all, bayes_out_crowd_all = naive_bayes_classifier(X_2D, y_crowd, crowd_all_idx)\n",
    "results['bayes_crowd_all'] = bayes_acc_crowd_all\n",
    "outputs.append(bayes_out_crowd_all)\n",
    "\n",
    "print(\"=== Results on combined all ===\")\n",
    "bayes_acc_combined_all, bayes_out_combined_all = naive_bayes_classifier(X_2D, y_combined, combined_all_idx)\n",
    "results['bayes_combined_all'] = bayes_acc_combined_all\n",
    "outputs.append(bayes_out_combined_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on incremental learning ===\n"
     ]
    }
   ],
   "source": [
    "# incremental learning\n",
    "print(\"=== Results on incremental learning ===\")\n",
    "bayes_acc_inc, bayes_out_inc = naive_bayes_classifier_incremental(X_2D, y_combined, experts_pilot_idx, crowd_all_idx)\n",
    "results['bayes_inc'] = bayes_acc_inc\n",
    "outputs.append(bayes_out_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = [100, 250, 500, 750, 1000, 2000]\n",
    "\n",
    "def random_forest_classifier(X, y, index, n_estimators):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = X.shape[0]   \n",
    "\n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    for fold_i in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        train_split, test_split = create_splits(y, 0.2)\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "        model.fit(X[train_split], y[train_split])\n",
    "        y_hat = model.predict(X[test_split])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[test_split], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, index[test_split]] = y_hat\n",
    "        \n",
    "    return (scores, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 100 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 250 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:15<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:14<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:18<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:17<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 500 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:27<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:48<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:32<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [01:35<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 750 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [03:21<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:23<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:10<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:04<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 1000 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:33<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:33<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [02:44<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "number of estimators: 2000 =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [05:08<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [05:07<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [05:29<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [05:33<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in N_ESTIMATORS:\n",
    "    print(\"\\n\\nnumber of estimators: %d =================================\\n\" % n_estimators)\n",
    "    \n",
    "    print(\"=== Results on expert pilot ===\", flush=True)\n",
    "    forest_acc_experts_pilot, forest_out_experts_pilot = random_forest_classifier(X_2D, y_experts, experts_pilot_idx, n_estimators)\n",
    "    results['forest_experts_pilot_%d' % n_estimators] = forest_acc_experts_pilot\n",
    "    outputs.append(forest_out_experts_pilot)\n",
    "\n",
    "    print(\"=== Results on crowd pilot ===\", flush=True)\n",
    "    forest_acc_crowd_pilot, forest_out_crowd_pilot = random_forest_classifier(X_2D, y_crowd, crowd_pilot_idx, n_estimators)\n",
    "    results['forest_crowd_pilot_%d' % n_estimators] = forest_acc_crowd_pilot\n",
    "    outputs.append(forest_out_crowd_pilot)\n",
    "\n",
    "    print(\"=== Results on crowd all ===\", flush=True)\n",
    "    forest_acc_crowd_all, forest_out_crowd_all = random_forest_classifier(X_2D, y_crowd, crowd_all_idx, n_estimators)\n",
    "    results['forest_crowd_all_%d' % n_estimators] = forest_acc_crowd_all\n",
    "    outputs.append(forest_out_crowd_all)\n",
    "\n",
    "    print(\"=== Results on combined all ===\", flush=True)\n",
    "    forest_acc_combined_all, forest_out_combined_all = random_forest_classifier(X_2D, y_combined, combined_all_idx, n_estimators)\n",
    "    results['forest_combined_all_%d' % n_estimators] =  forest_acc_combined_all\n",
    "    outputs.append(forest_out_combined_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def svmc(X, y, index, kernel='linear'):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = X.shape[0]   \n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    for fold_i in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        train_split, test_split = create_splits(y, 0.2)\n",
    "        \n",
    "        model = svm.SVC(kernel=kernel).fit(X[train_split], y[train_split])\n",
    "        y_hat = model.predict(X[test_split])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[test_split], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, index[test_split]] = y_hat\n",
    "        \n",
    "    return (scores, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "kernel: linear =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 405.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 532.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:02<00:00, 37.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:01<00:00, 51.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "kernel: rbf =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 751.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 751.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 460.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 426.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "kernel: poly =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 752.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 732.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 465.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 541.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "kernel: sigmoid =================================\n",
      "\n",
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 730.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 729.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 437.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:00<00:00, 425.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n",
    "    print(\"\\n\\nkernel: %s =================================\\n\" % kernel, flush=True)\n",
    "    \n",
    "    print(\"=== Results on expert pilot ===\", flush=True)\n",
    "    svm_acc_experts_pilot, svm_out_experts_pilot = svmc(X_2D, y_experts, experts_pilot_idx, kernel)\n",
    "    results['svm_experts_pilot_%s' % kernel] = svm_acc_experts_pilot\n",
    "    outputs.append(svm_out_experts_pilot)\n",
    "\n",
    "    print(\"=== Results on crowd pilot ===\", flush=True)\n",
    "    svm_acc_crowd_pilot, svm_out_crowd_pilot = svmc(X_2D, y_crowd, crowd_pilot_idx, kernel)\n",
    "    results['svm_crowd_pilot_%s' % kernel] = svm_acc_crowd_pilot\n",
    "    outputs.append(svm_out_crowd_pilot)\n",
    "\n",
    "    print(\"=== Results on crowd all ===\", flush=True)\n",
    "    svm_acc_crowd_all, svm_out_crowd_all = svmc(X_2D, y_crowd, crowd_all_idx, kernel)\n",
    "    results['svm_crowd_all_%s' % kernel] = svm_acc_crowd_all\n",
    "    outputs.append(svm_out_crowd_all)\n",
    "\n",
    "    print(\"=== Results on combined all ===\", flush=True)\n",
    "    svm_acc_combined_all, svm_out_combined_all = svmc(X_2D, y_combined, combined_all_idx, kernel)\n",
    "    results['svm_combined_all_%s' % kernel] = svm_acc_combined_all\n",
    "    outputs.append(svm_out_combined_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "N_EPOCH = 1000\n",
    "    \n",
    "def nn(X, y, index):\n",
    "    N_FOLDS = 100\n",
    "    n_samples = X.shape[0]   \n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    \n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    for fold_i in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        train_split, test_split = create_splits(y, 0.2)\n",
    "        \n",
    "        model = MLPClassifier(solver='adam', alpha=1e-5, \n",
    "                              learning_rate='adaptive',\n",
    "                              max_iter=N_EPOCH,\n",
    "                              hidden_layer_sizes=(20, 8))\n",
    "        model.fit(X[train_split], y[train_split])\n",
    "        y_hat = model.predict(X[test_split])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[test_split], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, index[test_split]] = y_hat\n",
    "        \n",
    "    return (scores, output)\n",
    "\n",
    "def nn_incremental(X, y, idx_experts, idx_crowd):\n",
    "    N_FOLDS = 100    \n",
    "    \n",
    "    n_samples = y.shape[0]   \n",
    "    output = -np.ones((N_FOLDS, n_samples))\n",
    "    scores = np.zeros(N_FOLDS)\n",
    "    for fold_i in tqdm(range(N_FOLDS), total=N_FOLDS):\n",
    "        idx_crowd_unique = np.setdiff1d(idx_crowd, idx_experts)\n",
    "        crowd_num_samples = idx_crowd_unique.shape[0]\n",
    "        experts_num_samples = idx_experts.shape[0]\n",
    "        \n",
    "        experts_train_split = np.random.choice(idx_experts,\n",
    "                                               int(experts_num_samples*.8),\n",
    "                                               replace=False)\n",
    "        experts_test_split = np.setdiff1d(idx_experts, experts_train_split)\n",
    "\n",
    "        crowd_train_split = np.random.choice(idx_crowd_unique,\n",
    "                                             int(crowd_num_samples*.8),\n",
    "                                             replace=False)\n",
    "        crowd_test_split = np.setdiff1d(idx_crowd_unique, crowd_train_split)\n",
    "        \n",
    "        idx_test = np.union1d(experts_test_split, crowd_test_split)\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            model = MLPClassifier(solver='adam', alpha=1e-5, \n",
    "                              learning_rate='adaptive',\n",
    "                              max_iter=N_EPOCH,\n",
    "                              hidden_layer_sizes=(20, 8))       \n",
    "            model.fit(X[experts_train_split], y[experts_train_split])\n",
    "            for i in range(N_EPOCH):\n",
    "                model.partial_fit(X[crowd_train_split], y[crowd_train_split], np.unique(y[idx_experts]))\n",
    "            \n",
    "            y_hat = model.predict(X[idx_test])\n",
    "        \n",
    "        fold_acc = accuracy_score(y[idx_test], y_hat)\n",
    "        scores[fold_i] = fold_acc\n",
    "        output[fold_i, idx_test] = y_hat\n",
    "        \n",
    "    return (scores, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd pilot ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on crowd all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:35<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on combined all ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 100/100 [00:36<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results on expert pilot ===\", flush=True)\n",
    "nn_experts_pilot, nn_out_experts_pilot = nn(X_2D, y_experts, experts_pilot_idx)\n",
    "results['nn_experts_pilot'] = nn_experts_pilot\n",
    "outputs.append(nn_out_experts_pilot)\n",
    "\n",
    "print(\"=== Results on crowd pilot ===\", flush=True)\n",
    "nn_crowd_pilot, nn_out_crowd_pilot = nn(X_2D, y_crowd, crowd_pilot_idx)\n",
    "results['nn_crowd_pilot'] = nn_crowd_pilot\n",
    "outputs.append(nn_out_crowd_pilot)\n",
    "\n",
    "print(\"=== Results on crowd all ===\", flush=True)\n",
    "nn_crowd_all, nn_out_crowd_all = nn(X_2D, y_crowd, crowd_all_idx)\n",
    "results['nn_crowd_all'] = nn_crowd_all\n",
    "outputs.append(nn_out_crowd_all)\n",
    "\n",
    "print(\"=== Results on combined all ===\", flush=True)\n",
    "nn_combined_all, nn_out_combined_all = nn(X_2D, y_combined, combined_all_idx)\n",
    "results['nn_combined_all'] = nn_combined_all\n",
    "outputs.append(nn_out_combined_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on incremental learning ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:25<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# incremental learning\n",
    "print(\"=== Results on incremental learning ===\", flush=True)\n",
    "nn_inc, nn_out_inc = nn_incremental(X_2D, y_combined, experts_pilot_idx, crowd_all_idx)\n",
    "results['nn_inc'] = nn_inc\n",
    "outputs.append(nn_out_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.to_csv(RESULTS_FILE, sep='\\t', index=False)  # tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array(outputs)\n",
    "np.savez_compressed(OUTPUT_FILE, predictions = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
