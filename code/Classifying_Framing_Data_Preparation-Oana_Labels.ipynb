{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying framing in videos\n",
    "\n",
    "Our aim is to investigate whether we can determine the kind of framing, episodic or thematic, that is used in news videos. \n",
    "\n",
    "## Limitations\n",
    "\n",
    "Only a small number of labeled samples are available, even less of which have been labeled by experts (as opposed to the crowd). This places a higher bound on the generalizability of our models, and makes it more challenging to train deep models. Therefor, this will serve as a proof-of-concept study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xander/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/xander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## prequisites\n",
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install gensim\n",
    "#%pip install nltk\n",
    "\n",
    "## libraries\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "VIDEO_METADATA = DATA_DIR + \"2014_metadata.csv\"\n",
    "VIDEO_TRANSCRIPTIONS = DATA_DIR + \"2014_transcripts_months_1to4.csv\"\n",
    "CROWD_RESULTS = DATA_DIR + \"120CSexperimentCrowdResults.csv\"\n",
    "CROWD_FILTERS = DATA_DIR + \"crowd_data_filtered_worker_ip_and_gender_and_type_and_title.csv\"\n",
    "EXPERT_RESULTS = DATA_DIR + \"expert_annotations_aggregated.csv\"\n",
    "DATA_NPZ = DATA_DIR + \"data.npz\"\n",
    "WORDVECTORS_KV = DATA_DIR + \"wordvectors.kv\"\n",
    "\n",
    "## load files\n",
    "video_metadata = pd.read_csv(VIDEO_METADATA, delimiter=';')\n",
    "video_transcriptions = pd.read_csv(VIDEO_TRANSCRIPTIONS)\n",
    "crowd_results = pd.read_csv(CROWD_RESULTS, delimiter=';')\n",
    "expert_results = pd.read_csv(EXPERT_RESULTS)\n",
    "crowd_filters = pd.read_csv(CROWD_FILTERS)\n",
    "\n",
    "## download wordnet vocabulary used in preprocessing the transcriptions\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "#set_seed(47)  # make reproducable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproces Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowd responses: 1860\n",
      "Crowd responses remain after filtering: 930\n"
     ]
    }
   ],
   "source": [
    "## Filter crowd?\n",
    "print(\"Crowd responses: %i\" % len(crowd_results))\n",
    "if True:\n",
    "    good_raters = np.unique(crowd_filters['_worker_id'].values)\n",
    "    crowd_results = crowd_results[crowd_results['_worker_id'].isin(good_raters)]\n",
    "    print(\"Crowd responses remain after filtering: %i\" % len(crowd_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess sequences\n",
    "stemmer = WordNetLemmatizer()\n",
    "def prep_text(s):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', s)\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    doc_length = len(document)\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join([word for word in document if word not in stops])\n",
    "    \n",
    "    return (document, doc_length)\n",
    "\n",
    "## fix missing video IDs\n",
    "for index, row in crowd_results.loc[crowd_results['display_id'] == '#NAME?'].iterrows():\n",
    "    video_id = row['link'].lstrip('https://www.youtube.com/watch?v=')\n",
    "    crowd_results.loc[index, 'display_id'] = video_id\n",
    "\n",
    "## drop duplicates\n",
    "video_transcriptions = video_transcriptions.drop_duplicates(subset='display_id', keep='last')\n",
    "video_metadata = video_metadata.drop_duplicates(subset='display_id', keep='last')\n",
    "\n",
    "## remove rows with missing transcriptions\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['clean_text'].notna()]\n",
    "\n",
    "## remove meta data entries that we don't have transcriptions for\n",
    "video_ids = np.intersect1d(video_metadata['display_id'].values, video_transcriptions['display_id'].values)\n",
    "video_metadata = video_metadata[video_metadata['display_id'].isin(video_ids)]\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['display_id'].isin(video_ids)]\n",
    "\n",
    "assert(len(video_metadata) == len(video_transcriptions))\n",
    "\n",
    "## process text\n",
    "for index, row in video_transcriptions.iterrows():\n",
    "    text = row['clean_text']\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_transcriptions.loc[index, 'clean_text'] = text_processed\n",
    "  \n",
    "for index, row in video_metadata.iterrows():\n",
    "    for label in ['fulltitle', 'description']:\n",
    "        text = row[label]\n",
    "        text_processed, nwords = prep_text(text)\n",
    "        video_metadata.loc[index, label] = text_processed\n",
    "\n",
    "    text = ' '.join([tag for tag in row['tags'].split('+')])\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_metadata.loc[index, 'tags'] = text_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Metadata\n",
      "======================================================================\n",
      "display_id                                                    oO-k-9ZLLLk\n",
      "title                               Drive it! from 22.04.2014 | Drive it!\n",
      "fulltitle                                          drive 22 04 2014 drive\n",
      "description             drive week mercedes truck rally racer latest a...\n",
      "upload_date                                                    2014-04-23\n",
      "duration                                                             1219\n",
      "uploader                                                       DW English\n",
      "thumbnail               https://i.ytimg.com/vi/oO-k-9ZLLLk/maxresdefau...\n",
      "tags                    audi s1 audi quattro s1 racing car honda civic...\n",
      "categories                                               Autos & Vehicles\n",
      "average_rating                                                          5\n",
      "view_count                                                            484\n",
      "like_count                                                              7\n",
      "dislike_count                                                           0\n",
      "width                                                                1280\n",
      "height                                                                720\n",
      "ext                                                                   mp4\n",
      "format                                              22 - 1280x720 (hd720)\n",
      "acodec                                                          mp4a.40.2\n",
      "vcodec                                                        avc1.64001F\n",
      "automatic_captions                                                      1\n",
      "subtitles                                                               0\n",
      "year                                                                 2014\n",
      "month                                                                   4\n",
      "day                                                                    23\n",
      "date_short                                                       4/1/2014\n",
      "crimea_check                                                            0\n",
      "syria_check                                                             0\n",
      "mh17_check                                                              0\n",
      "filter_$                                                                0\n",
      "cnn_collection_check                                                    0\n",
      "tagcount                                                               14\n",
      "duration_min                                             20,3166666666667\n",
      "duration_min_rnd1                                                      20\n",
      "green_men_check                                                         0\n",
      "volunteers_check                                                        0\n",
      "annex_check                                                             0\n",
      "selfd_check                                                             0\n",
      "indep_check                                                             0\n",
      "down_check                                                              0\n",
      "crash_check                                                             0\n",
      "attack_check                                                            0\n",
      "illegal_check                                                           0\n",
      "legal_check                                                             0\n",
      "nation_check                                                            0\n",
      "patriot_check                                                           0\n",
      "fascist_check                                                           0\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Video Transcriptions\n",
      "======================================================================\n",
      "display_id                                            RBXmM5BizNY\n",
      "title                                01/08/2014 THE DEBATE part 1\n",
      "uploader                                        FRANCE 24 English\n",
      "upload_date                                              20140110\n",
      "is_source_yt                                                    0\n",
      "is_source_bg                                                    1\n",
      "is_missing                                                      0\n",
      "clean_text      neither side blinking turkey ruling ak party c...\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Crowd Results\n",
      "======================================================================\n",
      "_trust                                                            0.5357\n",
      "_worker_id                                                      45527958\n",
      "_country                                                             EGY\n",
      "_region                                                                5\n",
      "_city                                                              Tanta\n",
      "_ip                                                       197.246.228.58\n",
      "gender                                                              male\n",
      "VideoPortionWatched                               only_part_of_the_video\n",
      "Trustworthiness                                                        4\n",
      "Emotion                                                                5\n",
      "VideoCategory                                                 world_news\n",
      "Frame                                                                  4\n",
      "PersonalStory                                                        yes\n",
      "NoteworthyKeywords     NASA suspends ties with Russia over Ukraine, s...\n",
      "Dominant_Frame                                                  episodic\n",
      "VideoTitle             NASA SUSPENDS TIES WITH RUSSIA OVER UKRAINE, S...\n",
      "ImagesVSWords                                                      words\n",
      "display_id                                                   aWqZ5WHQrzg\n",
      "link                         https://www.youtube.com/watch?v=aWqZ5WHQrzg\n",
      "Channels                                                              RT\n",
      "Name: 6, dtype: object\n",
      "\n",
      "Expert Results\n",
      "======================================================================\n",
      "display_id                                                       -7xsam1-KSQ\n",
      "title                                Russian nostalgia over Crimea vacations\n",
      "fulltitle                            Russian nostalgia over Crimea vacations\n",
      "description                Many in Crimea favour Russia over Ukraine and ...\n",
      "upload_date                                                       2014-03-12\n",
      "duration                                                                 179\n",
      "uploader                                                  Al Jazeera English\n",
      "thumbnail                  https://i.ytimg.com/vi/-7xsam1-KSQ/maxresdefau...\n",
      "tags                       3328932389001+Crimea+package+Europe+Al Jazeera...\n",
      "categories                                                   News & Politics\n",
      "framing_type                                                        Episodic\n",
      "framing_score                                                              6\n",
      "story_present                                                            Yes\n",
      "watch_full_video                                                         Yes\n",
      "framing_reason                                              Images and words\n",
      "sentiment_present                                                        Yes\n",
      "sentiment_label                                                     Positive\n",
      "sentiment_magnitude                                                        *\n",
      "trustworthiness                                                            6\n",
      "framing_type_all                                Thematic, Episodic, Episodic\n",
      "framing_score_all                                                    3, 6, 6\n",
      "story_present_all                                              Yes, Yes, Yes\n",
      "watch_full_video_all                                            Yes, No, Yes\n",
      "framing_reason_all         Images and words, Images and words, Images and...\n",
      "sentiment_present_all                                          Yes, Yes, Yes\n",
      "sentiment_label_all                             Positive, Positive, Positive\n",
      "sentiment_magnitude_all                                            4.0, *, *\n",
      "trustworthiness_all                                                  6, 4, 6\n",
      "full_agreement                                                             0\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Statistics\n",
      "======================================================================\n",
      " - experts watched 58 videos (1.0 average labels per video)\n",
      "   58 of which are part of our 120 videos dataset\n",
      " - crowd watched 119 videos (7.815126050420168 average labels per video)\n",
      "   119 of which are part of our 120 videos dataset\n",
      "   58 of which are also labeled by our experts\n"
     ]
    }
   ],
   "source": [
    "print(\"Video Metadata\\n\" + '='*70)\n",
    "print(video_metadata.iloc[1])\n",
    "\n",
    "print(\"\\nVideo Transcriptions\\n\" + '='*70)\n",
    "print(video_transcriptions.iloc[1])\n",
    "\n",
    "print(\"\\nCrowd Results\\n\" + '='*70)\n",
    "print(crowd_results.iloc[1])\n",
    "\n",
    "print(\"\\nExpert Results\\n\" + '='*70)\n",
    "print(expert_results.iloc[1])\n",
    "\n",
    "print(\"\\nStatistics\\n\" + '='*70)\n",
    "crowd_labels_per_video = crowd_results['display_id'].value_counts().values\n",
    "expert_labels_per_video = expert_results['display_id'].value_counts().values\n",
    "crowd_videos_uniq = np.unique(crowd_results['display_id'].values)\n",
    "expert_videos_uniq = np.unique(expert_results['display_id'].values)\n",
    "print(\" - experts watched {} videos ({} average labels per video)\".format(expert_videos_uniq.shape[0],\n",
    "                                                                          expert_labels_per_video.sum()/expert_labels_per_video.shape[0]))\n",
    "print(\"   {} of which are part of our 120 videos dataset\".format(np.isin(expert_videos_uniq,\n",
    "                                                                         video_transcriptions['display_id']).sum()))\n",
    "print(\" - crowd watched {} videos ({} average labels per video)\".format(crowd_videos_uniq.shape[0],\n",
    "                                                                        crowd_labels_per_video.sum()/crowd_labels_per_video.shape[0]))\n",
    "print(\"   {} of which are part of our 120 videos dataset\".format(np.isin(crowd_videos_uniq,\n",
    "                                                                         video_transcriptions['display_id']).sum()))\n",
    "print(\"   {} of which are also labeled by our experts\".format(np.isin(expert_videos_uniq,\n",
    "                                                                      crowd_videos_uniq).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Our input data consist of the concatenation of transcriptions, titles, descriptions, and tags---all of which can be acquired from the video. For our traditional machine learning models we need a 1-dimensional fixed-length input vector per sequence, which are learned using Doc2Vec. A 2-dimensional variable-width vector per sequence will be used for our deep models, for which we use pre-trained Word2Vec vectors.\n",
    "\n",
    "In all cases we use the framing score as labels, which are defined on a Likert scale from 1 (centainly thematic) to 7 (centainly episodic). We use a majority vote when labels for the same video differ. If no majority exists, then we take either the mid point (eg, 3 and 5 results in 4), or a random choice from the equal splits if that is not possible.\n",
    "\n",
    "## Incremental learning\n",
    "\n",
    "With incremental learning, we further train a model as more data becomes available. In our case, we first train a model using purely the labels provided by experts. Once trained and tested, we move over to the crowd data, and use their labels to improve the model. As experts are expensive and crowd workers are cheap, we hope to see that we can lower costs by giving our model a jump start with few but high-quality expensive labels, and then finetune it with larger amounts of lower-quality but much cheaper labels. \n",
    "\n",
    "We also train another model using purely the labels from the crowd, and test on those from the experts. Here, we treat the expert labels as gold standard. This experiment will give us an idea of the quality of crowd sourced labels, and whether we can do without expert annotations by accepting a (small?) loss in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert text to tensor of size NUM_SEQUENCES x MAX_SEQUENCE_LENGTH x 300\n",
    "def vectorize_sequences3D(sequences, sequence_length, vector_length=300):\n",
    "    n = sequences.shape[0]\n",
    "    a = np.zeros((n, sequence_length, vector_length))  # time on vertical axis; zero padding\n",
    "    for i, terms in enumerate(sequences):\n",
    "        nterms = len(terms)\n",
    "        for j, term in enumerate(terms):\n",
    "            try:\n",
    "                wv = w2v_model[term][:vector_length]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            a[i, j, :] = wv\n",
    "                    \n",
    "    return a\n",
    "\n",
    "## convert text to matrix of size NUM_SEQUENCES x 300 \n",
    "def vectorize_sequences2D(sequences, model, vector_length=300):\n",
    "    a = np.zeros((sequences.shape[0], vector_length))\n",
    "    for i, terms in enumerate(sequences):\n",
    "        a[i] = model.infer_vector([term for term in terms if len(term) > 0])\n",
    "        \n",
    "    return a\n",
    "\n",
    "## learn word embeddings using Word2vec\n",
    "def train_word_embeddings(sequences, vector_length=25):\n",
    "    return Word2Vec(sequences, size=vector_length, workers=4)\n",
    "\n",
    "## learn sequence vectors using Doc2Vec\n",
    "def train_sequence_embeddings(sequences, train_idx, test_idx, vector_length=300):\n",
    "    train_corpus = list()\n",
    "    test_corpus = list()\n",
    "    for i, terms in enumerate(sequences):\n",
    "        terms = [term for term in terms if len(terms) > 0]\n",
    "        if i in train_idx:\n",
    "            train_corpus.append(TaggedDocument(terms, [i]))\n",
    "        elif i in test_idx:\n",
    "            test_corpus.append(terms)\n",
    "            \n",
    "    model = Doc2Vec(vector_size=vector_length, min_count=2, epochs=100)\n",
    "    model.build_vocab(train_corpus)\n",
    "    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    return model   \n",
    "\n",
    "## return majority class per video or, if no majority, return mid point if exists, \n",
    "## else return random selection from most common score\n",
    "def create_targets(video_ids, annotations):\n",
    "    labels = {display_id: [] for display_id in video_ids}\n",
    "    for index, row in annotations.iterrows():\n",
    "        labels[row['display_id']].append(row['Frame'])\n",
    "    \n",
    "    targets = dict()\n",
    "    for display_id, label_set in labels.items():\n",
    "        ct = Counter(label_set)\n",
    "        ct_max = max(ct.values())\n",
    "        majority_vote = [label for label, count in ct.items() if count == ct_max]\n",
    "        \n",
    "        if len(majority_vote) == 1:\n",
    "            targets[display_id] = majority_vote[0]\n",
    "        else:  # different labels with same number of votes\n",
    "            mid_point = sum(majority_vote)/len(majority_vote)\n",
    "            if mid_point.is_integer():  # whole number\n",
    "                targets[display_id] = int(mid_point)\n",
    "            else:  # random selection\n",
    "                targets[display_id] = np.random.choice(majority_vote)\n",
    "                \n",
    "    return targets\n",
    "\n",
    "def create_splits(n):\n",
    "    sample_idx = np.arange(n)\n",
    "    np.random.shuffle(sample_idx)\n",
    "    \n",
    "    return (sample_idx[:int(n*0.8)], sample_idx[int(n*0.8):])\n",
    "\n",
    "def tf_idf_ranked(sequences, top_k=25, at_least=2):\n",
    "    \"\"\"return top_k terms, weighted bt TF-IDF, per sequence, ordered from high to low, so \n",
    "       that index 0 of each sequence holds the most relevant term\"\"\"\n",
    "    tf_list = list()\n",
    "    df = dict()\n",
    "    num_sequences = sequences.shape[0]\n",
    "    for seq in sequences:       \n",
    "        c = Counter(seq)\n",
    "        n = sum(c.values())\n",
    "        \n",
    "        tf = dict()\n",
    "        for term, freq in c.items():\n",
    "            if len(term) <= 0:\n",
    "                continue\n",
    "                \n",
    "            if freq >= at_least:\n",
    "                tf[term] = freq/n\n",
    "            if term not in df.keys():\n",
    "                df[term] = 1\n",
    "                continue\n",
    "            df[term] = df[term] + 1\n",
    "            \n",
    "        tf_list.append(tf)\n",
    "        \n",
    "    idf = dict()\n",
    "    for term, term_doc_freq in df.items():\n",
    "        idf[term] = log(num_sequences / term_doc_freq)\n",
    "        \n",
    "    tf_idf_list = list()\n",
    "    for tf in tf_list:\n",
    "        tf_idf = dict()\n",
    "        for term in tf.keys():\n",
    "            tf_idf[term] = tf[term]*idf[term]\n",
    "            \n",
    "        tf_idf_list.append([k for k,v in sorted(tf_idf.items(), key=lambda item: item[1])[:top_k]])\n",
    "    \n",
    "    return np.array(tf_idf_list)\n",
    "\n",
    "def mkdata_list(*args):\n",
    "    data = [list() for i in range(args[0].shape[0])]\n",
    "    for a in args:\n",
    "        slc = list()\n",
    "        max_length = 0\n",
    "        for row in a:\n",
    "            if len(row) <= 0:\n",
    "                continue\n",
    "                \n",
    "            s = row.split()\n",
    "            slc.append(s)\n",
    "            if len(s) > max_length:\n",
    "                max_length = len(s)\n",
    "                \n",
    "        for i, row in enumerate(slc):\n",
    "            if len(row) < max_length:\n",
    "                row.extend(['' for k in range(max_length-len(row))])\n",
    "                data[i].extend(row)\n",
    "                \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Word2Vec model\n",
      "training Doc2Vec model\n",
      "vectorizing 2D data\n",
      "vectorizing 3D data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a934d94afc8f>:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  wv = w2v_model[term][:vector_length]\n"
     ]
    }
   ],
   "source": [
    "## sort using same index so video_metadate[i] matches video_transcriptions[i]\n",
    "video_metadata = video_metadata.sort_values(by=['display_id'])\n",
    "video_transcriptions = video_transcriptions.set_index('display_id')\n",
    "video_transcriptions = video_transcriptions.reindex(index=video_metadata['display_id'])\n",
    "video_transcriptions = video_transcriptions.reset_index()\n",
    "\n",
    "## create mappings\n",
    "video_idx_map = {display_id: i for i, display_id in enumerate(video_metadata['display_id'].values)}\n",
    "idx_video_map = {i: display_id for display_id, i in video_idx_map.items()}\n",
    "labeled_samples_ids = np.union1d(crowd_videos_uniq, expert_videos_uniq)\n",
    "labeled_samples_idx = [idx for video_id, idx in video_idx_map.items()\n",
    "                            if video_id in labeled_samples_ids]\n",
    "\n",
    "## vectorize text sequences\n",
    "data = mkdata_list(video_metadata['fulltitle'].values,\n",
    "                   video_metadata['description'].values,\n",
    "                   video_metadata['tags'].values,\n",
    "                   video_transcriptions['clean_text'].values)\n",
    "print(\"training Word2Vec model\")\n",
    "w2v_model = train_word_embeddings(data)\n",
    "\n",
    "print(\"training Doc2Vec model\")\n",
    "train_idx, test_idx = create_splits(data.shape[0])\n",
    "d2v_model = train_sequence_embeddings(data,\n",
    "                                      train_idx=train_idx, test_idx=test_idx,\n",
    "                                      vector_length=w2v_model.vector_size)\n",
    "\n",
    "#data = tf_idf_ranked(data)  # only use most relevant words\n",
    "\n",
    "data = data[labeled_samples_idx]  # we no longer need the unlabeled data\n",
    "data_length = max(map(len, data))  # maximum row length\n",
    "labeled_videos_idx_map = {idx_video_map[i]: j for j, i in enumerate(labeled_samples_idx)}\n",
    "idx_labeled_videos_map = {i: display_id for display_id, i in labeled_videos_idx_map.items()}\n",
    "\n",
    "print(\"vectorizing 2D data\")\n",
    "X_2D = vectorize_sequences2D(data,\n",
    "                             d2v_model,\n",
    "                             vector_length=w2v_model.vector_size)\n",
    "        \n",
    "print(\"vectorizing 3D data\")\n",
    "X_3D = vectorize_sequences3D(data,\n",
    "                             sequence_length=data_length,\n",
    "                             vector_length=w2v_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data.shape[0]\n",
    "\n",
    "## generate labels - 7 point Likert scale\n",
    "y_likert_crowd = -np.ones(num_samples)\n",
    "for video_id, label in create_targets(crowd_videos_uniq, crowd_results).items():\n",
    "    y_likert_crowd[labeled_videos_idx_map[video_id]] = label - 1  # 0-based\n",
    "    \n",
    "y_likert_experts = -np.ones(num_samples)\n",
    "for _, row in expert_results.iterrows():\n",
    "    y_likert_experts[labeled_videos_idx_map[row.display_id]] = row.framing_score - 1  # 0-based\n",
    "    \n",
    "## alternate labels - binary classification of framing type\n",
    "y_dominant_crowd = -np.ones(num_samples)\n",
    "for i in range(y_likert_crowd.shape[0]):\n",
    "    if y_likert_crowd[i] < 0:\n",
    "        continue\n",
    "    if y_likert_crowd[i] < 3:\n",
    "        y_dominant_crowd[i] = 0\n",
    "    elif y_likert_crowd[i] > 3:\n",
    "        y_dominant_crowd[i] = 1\n",
    "\n",
    "y_dominant_experts = -np.ones(num_samples)\n",
    "for _, row in expert_results.iterrows():\n",
    "    framing_type = 0 if row.framing_type == \"Thematic\" else 1  # if episodic\n",
    "    y_dominant_experts[labeled_videos_idx_map[row.display_id]] = framing_type\n",
    "        \n",
    "## combined set - no distinction between experts and crowd\n",
    "y_likert_combined = np.copy(y_likert_experts)  # expert labels are preferred\n",
    "copy_idx = np.where(y_likert_combined == -1)[0]\n",
    "y_likert_combined[copy_idx] = y_likert_crowd[copy_idx]\n",
    "\n",
    "y_dominant_combined = np.copy(y_dominant_experts)  # expert labels are preferred\n",
    "copy_idx = np.where(y_dominant_combined == -1)[0]\n",
    "y_dominant_combined[copy_idx] = y_dominant_crowd[copy_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(DATA_NPZ,\n",
    "                    X_2D = X_2D,\n",
    "                    X_3D = X_3D,\n",
    "                    y_likert_crowd = y_likert_crowd,\n",
    "                    y_likert_experts = y_likert_experts,\n",
    "                    y_dominant_crowd = y_dominant_crowd,\n",
    "                    y_dominant_experts = y_dominant_experts,\n",
    "                    y_likert_combined = y_likert_combined,\n",
    "                    y_dominant_combined = y_dominant_combined)\n",
    "w2v_model.wv.save(WORDVECTORS_KV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
