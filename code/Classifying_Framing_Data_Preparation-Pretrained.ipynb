{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying framing in videos\n",
    "\n",
    "Our aim is to investigate whether we can determine the kind of framing, episodic or thematic, that is used in news videos. \n",
    "\n",
    "## Limitations\n",
    "\n",
    "Only a small number of labeled samples are available, even less of which have been labeled by experts (as opposed to the crowd). This places a higher bound on the generalizability of our models, and makes it more challenging to train deep models. Therefor, this will serve as a proof-of-concept study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xander/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## prequisites\n",
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install gensim\n",
    "#%pip install nltk\n",
    "\n",
    "## libraries\n",
    "from collections import Counter\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim.models.keyedvectors as w2v\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "VIDEO_METADATA = DATA_DIR + \"2014_metadata.csv\"\n",
    "VIDEO_TRANSCRIPTIONS = DATA_DIR + \"2014_transcripts_months_1to4.csv\"\n",
    "CROWD_RESULTS = DATA_DIR + \"120CSexperimentCrowdResults.csv\"\n",
    "EXPERT_RESULTS = DATA_DIR + \"ExpertAnnotationsEpisodicVSThematic.tsv\"\n",
    "DATA_NPZ = DATA_DIR + \"data.npz\"\n",
    "\n",
    "## load files\n",
    "video_metadata = pd.read_csv(VIDEO_METADATA, delimiter=';')\n",
    "video_transcriptions = pd.read_csv(VIDEO_TRANSCRIPTIONS)\n",
    "crowd_results = pd.read_csv(CROWD_RESULTS, delimiter=';')\n",
    "expert_results = pd.read_csv(EXPERT_RESULTS, delimiter='\\t')\n",
    "\n",
    "## download wordnet vocabulary used in preprocessing the transcriptions\n",
    "nltk.download('wordnet')\n",
    "\n",
    "## download and load pretrained word2vec model (1.5G)\n",
    "w2v_model_file = DATA_DIR+\"GoogleNews-vectors-negative300.bin\"\n",
    "if not os.path.isfile(w2v_model_file):\n",
    "    #!curl --output w2v_model_file+'gz' https://doc-14-ao-docs.googleusercontent.com/docs/securesc/99jsqd47v0odop6oamsp9gu5avjncnu2/kkmik6pqg8sde0o0dek2kmb2utjjvvsf/1585302525000/06848720943842814915/17947136028472191799Z/0B7XkCwpI5KDYNlNUTTlSS21pQmM?e=download&nonce=thttca6mq83oc&user=17947136028472191799Z&hash=54alve1ruloh9v1lr2k6ciphbrvpadfr'\n",
    "    !gunzip w2v_model_file+'.gz'\n",
    "\n",
    "w2v_model = w2v.KeyedVectors.load_word2vec_format(w2v_model_file, binary=True)  # may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_seed(47)  # make reproducable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproces Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess sequences\n",
    "stemmer = WordNetLemmatizer()\n",
    "def prep_text(s):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', s)\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    doc_length = len(document)\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    return (document, doc_length)\n",
    "\n",
    "## fix missing video IDs\n",
    "for index, row in crowd_results.loc[crowd_results['display_id'] == '#NAME?'].iterrows():\n",
    "    video_id = row['link'].lstrip('https://www.youtube.com/watch?v=')\n",
    "    crowd_results.loc[index, 'display_id'] = video_id\n",
    "\n",
    "## use same labels as crowd results\n",
    "expert_results.columns = ['display_id', 'annotator', 'VideoTitle', 'link', 'Frame', 'Dominant_Frame', \n",
    "                           'PersonalStory', 'VideoPortionWatched', 'NoteworthyKeywords', 'ImagesVSWords',\n",
    "                           'evokes_emotion', 'emotion_type', 'Emotion', 'Trustworthiness', 'comment']\n",
    "\n",
    "## drop duplicates\n",
    "video_transcriptions = video_transcriptions.drop_duplicates(subset='display_id', keep='last')\n",
    "video_metadata = video_metadata.drop_duplicates(subset='display_id', keep='last')\n",
    "\n",
    "## remove rows with missing transcriptions\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['clean_text'].notna()]\n",
    "\n",
    "## remove meta data entries that we don't have transcriptions for\n",
    "video_ids = np.intersect1d(video_metadata['display_id'].values, video_transcriptions['display_id'].values)\n",
    "video_metadata = video_metadata[video_metadata['display_id'].isin(video_ids)]\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['display_id'].isin(video_ids)]\n",
    "\n",
    "assert(len(video_metadata) == len(video_transcriptions))\n",
    "\n",
    "## process text\n",
    "for index, row in video_transcriptions.iterrows():\n",
    "    text = row['clean_text']\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_transcriptions.loc[index, 'clean_text'] = text_processed\n",
    "  \n",
    "for index, row in video_metadata.iterrows():\n",
    "    for label in ['fulltitle', 'description']:\n",
    "        text = row[label]\n",
    "        text_processed, nwords = prep_text(text)\n",
    "        video_metadata.loc[index, label] = text_processed\n",
    "\n",
    "    text = ' '.join([tag for tag in row['tags'].split('+')])\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_metadata.loc[index, 'tags'] = text_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Metadata\n",
      "======================================================================\n",
      "display_id                                                    oO-k-9ZLLLk\n",
      "title                               Drive it! from 22.04.2014 | Drive it!\n",
      "fulltitle                               drive it from 22 04 2014 drive it\n",
      "description             drive it is out and about this week with merce...\n",
      "upload_date                                                    2014-04-23\n",
      "duration                                                             1219\n",
      "uploader                                                       DW English\n",
      "thumbnail               https://i.ytimg.com/vi/oO-k-9ZLLLk/maxresdefau...\n",
      "tags                    audi s1 audi quattro s1 racing car honda civic...\n",
      "categories                                               Autos & Vehicles\n",
      "average_rating                                                          5\n",
      "view_count                                                            484\n",
      "like_count                                                              7\n",
      "dislike_count                                                           0\n",
      "width                                                                1280\n",
      "height                                                                720\n",
      "ext                                                                   mp4\n",
      "format                                              22 - 1280x720 (hd720)\n",
      "acodec                                                          mp4a.40.2\n",
      "vcodec                                                        avc1.64001F\n",
      "automatic_captions                                                      1\n",
      "subtitles                                                               0\n",
      "year                                                                 2014\n",
      "month                                                                   4\n",
      "day                                                                    23\n",
      "date_short                                                       4/1/2014\n",
      "crimea_check                                                            0\n",
      "syria_check                                                             0\n",
      "mh17_check                                                              0\n",
      "filter_$                                                                0\n",
      "cnn_collection_check                                                    0\n",
      "tagcount                                                               14\n",
      "duration_min                                             20,3166666666667\n",
      "duration_min_rnd1                                                      20\n",
      "green_men_check                                                         0\n",
      "volunteers_check                                                        0\n",
      "annex_check                                                             0\n",
      "selfd_check                                                             0\n",
      "indep_check                                                             0\n",
      "down_check                                                              0\n",
      "crash_check                                                             0\n",
      "attack_check                                                            0\n",
      "illegal_check                                                           0\n",
      "legal_check                                                             0\n",
      "nation_check                                                            0\n",
      "patriot_check                                                           0\n",
      "fascist_check                                                           0\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Video Transcriptions\n",
      "======================================================================\n",
      "display_id                                            RBXmM5BizNY\n",
      "title                                01/08/2014 THE DEBATE part 1\n",
      "uploader                                        FRANCE 24 English\n",
      "upload_date                                              20140110\n",
      "is_source_yt                                                    0\n",
      "is_source_bg                                                    1\n",
      "is_missing                                                      0\n",
      "clean_text      can neither side is blinking in turkey the rul...\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Crowd Results\n",
      "======================================================================\n",
      "_trust                                                            0.6948\n",
      "_worker_id                                                      45332221\n",
      "_country                                                             VEN\n",
      "_region                                                               14\n",
      "_city                                                            Mï¿½ï¿½\n",
      "_ip                                                        190.39.241.80\n",
      "gender                                                              male\n",
      "VideoPortionWatched                                          whole_video\n",
      "Trustworthiness                                                        7\n",
      "Emotion                                                                2\n",
      "VideoCategory                                                 world_news\n",
      "Frame                                                                  7\n",
      "PersonalStory                                                         no\n",
      "NoteworthyKeywords     Uncertainty grows among several countries in t...\n",
      "Dominant_Frame                                                  episodic\n",
      "VideoTitle             NASA SUSPENDS TIES WITH RUSSIA OVER UKRAINE, S...\n",
      "ImagesVSWords                                           images_and_words\n",
      "display_id                                                   aWqZ5WHQrzg\n",
      "link                         https://www.youtube.com/watch?v=aWqZ5WHQrzg\n",
      "Channels                                                              RT\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Expert Results\n",
      "======================================================================\n",
      "display_id                                                   -7xsam1-KSQ\n",
      "annotator                                                         Mykola\n",
      "VideoTitle                       Russian nostalgia over Crimea vacations\n",
      "link                         https://www.youtube.com/watch?v=-7xsam1-KSQ\n",
      "Frame                                                                  3\n",
      "Dominant_Frame                                                  Thematic\n",
      "PersonalStory                                                        Yes\n",
      "VideoPortionWatched                                                  Yes\n",
      "NoteworthyKeywords     Nostalgia, vacation, Crimea, Russia, Soviet Union\n",
      "ImagesVSWords                                           Images and words\n",
      "evokes_emotion                                                       Yes\n",
      "emotion_type                                                    Positive\n",
      "Emotion                                                                4\n",
      "Trustworthiness                                                        6\n",
      "comment                                                              NaN\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Statistics\n",
      "======================================================================\n",
      " - experts watched 58 videos (3.0 average labels per video)\n",
      "   58 of which are part of our 120 videos dataset\n",
      " - crowd watched 120 videos (15.5 average labels per video)\n",
      "   120 of which are part of our 120 videos dataset\n",
      "   58 of which are also labeled by our experts\n"
     ]
    }
   ],
   "source": [
    "print(\"Video Metadata\\n\" + '='*70)\n",
    "print(video_metadata.iloc[1])\n",
    "\n",
    "print(\"\\nVideo Transcriptions\\n\" + '='*70)\n",
    "print(video_transcriptions.iloc[1])\n",
    "\n",
    "print(\"\\nCrowd Results\\n\" + '='*70)\n",
    "print(crowd_results.iloc[1])\n",
    "\n",
    "print(\"\\nExpert Results\\n\" + '='*70)\n",
    "print(expert_results.iloc[1])\n",
    "\n",
    "print(\"\\nStatistics\\n\" + '='*70)\n",
    "crowd_labels_per_video = crowd_results['display_id'].value_counts().values\n",
    "expert_labels_per_video = expert_results['display_id'].value_counts().values\n",
    "crowd_videos_uniq = np.unique(crowd_results['display_id'].values)\n",
    "expert_videos_uniq = np.unique(expert_results['display_id'].values)\n",
    "print(\" - experts watched {} videos ({} average labels per video)\".format(expert_videos_uniq.shape[0],\n",
    "                                                                          expert_labels_per_video.sum()/expert_labels_per_video.shape[0]))\n",
    "print(\"   {} of which are part of our 120 videos dataset\".format(np.isin(expert_videos_uniq,\n",
    "                                                                         video_transcriptions['display_id']).sum()))\n",
    "print(\" - crowd watched {} videos ({} average labels per video)\".format(crowd_videos_uniq.shape[0],\n",
    "                                                                        crowd_labels_per_video.sum()/crowd_labels_per_video.shape[0]))\n",
    "print(\"   {} of which are part of our 120 videos dataset\".format(np.isin(crowd_videos_uniq,\n",
    "                                                                         video_transcriptions['display_id']).sum()))\n",
    "print(\"   {} of which are also labeled by our experts\".format(np.isin(expert_videos_uniq,\n",
    "                                                                      crowd_videos_uniq).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Our input data consist of the concatenation of transcriptions, titles, descriptions, and tags---all of which can be acquired from the video. For our traditional machine learning models we need a 1-dimensional fixed-length input vector per sequence, which are learned using Doc2Vec. A 2-dimensional variable-width vector per sequence will be used for our deep models, for which we use pre-trained Word2Vec vectors.\n",
    "\n",
    "In all cases we use the framing score as labels, which are defined on a Likert scale from 1 (centainly thematic) to 7 (centainly episodic). We use a majority vote when labels for the same video differ. If no majority exists, then we take either the mid point (eg, 3 and 5 results in 4), or a random choice from the equal splits if that is not possible.\n",
    "\n",
    "## Incremental learning\n",
    "\n",
    "With incremental learning, we further train a model as more data becomes available. In our case, we first train a model using purely the labels provided by experts. Once trained and tested, we move over to the crowd data, and use their labels to improve the model. As experts are expensive and crowd workers are cheap, we hope to see that we can lower costs by giving our model a jump start with few but high-quality expensive labels, and then finetune it with larger amounts of lower-quality but much cheaper labels. \n",
    "\n",
    "We also train another model using purely the labels from the crowd, and test on those from the experts. Here, we treat the expert labels as gold standard. This experiment will give us an idea of the quality of crowd sourced labels, and whether we can do without expert annotations by accepting a (small?) loss in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert text to tensor of size NUM_SEQUENCES x MAX_SEQUENCE_LENGTH x 300\n",
    "def vectorize_sequences3D(sequences, sequence_length, vector_length=300):\n",
    "    n = sequences.shape[0]\n",
    "    a = np.zeros((n, sequence_length, vector_length))  # time on vertical axis; zero padding\n",
    "    for i, seq in enumerate(sequences):\n",
    "        terms = seq.split()\n",
    "        nterms = len(terms)\n",
    "        for j, term in enumerate(terms):\n",
    "            try:\n",
    "                wv = w2v_model[term][:vector_length]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            a[i, j, :] = wv\n",
    "                    \n",
    "    return a\n",
    "\n",
    "## convert text to matrix of size NUM_SEQUENCES x 300 \n",
    "def vectorize_sequences2D(sequences, model, vector_length=300):\n",
    "    a = np.zeros((sequences.shape[0], vector_length))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        terms = seq.split()\n",
    "        a[i] = model.infer_vector(terms)\n",
    "        \n",
    "    return a\n",
    "\n",
    "## learn sequence vectors using Doc2Vec\n",
    "def train_sequence_embeddings(sequences, train_idx, test_idx, vector_length=300):\n",
    "    train_corpus = list()\n",
    "    test_corpus = list()\n",
    "    for i, seq in enumerate(sequences):\n",
    "        terms = seq.split()\n",
    "        if i in train_idx:\n",
    "            train_corpus.append(TaggedDocument(terms, [i]))\n",
    "        elif i in test_idx:\n",
    "            test_corpus.append(terms)\n",
    "            \n",
    "    model = Doc2Vec(vector_size=vector_length, min_count=2, epochs=50)\n",
    "    model.build_vocab(train_corpus)\n",
    "    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    return model   \n",
    "\n",
    "## return majority class per video or, if no majority, return mid point if exists, \n",
    "## else return random selection from most common score\n",
    "def create_targets(video_ids, annotations):\n",
    "    labels = {display_id: [] for display_id in video_ids}\n",
    "    for index, row in annotations.iterrows():\n",
    "        labels[row['display_id']].append(row['Frame'])\n",
    "    \n",
    "    targets = dict()\n",
    "    for display_id, label_set in labels.items():\n",
    "        ct = Counter(label_set)\n",
    "        ct_max = max(ct.values())\n",
    "        majority_vote = [label for label, count in ct.items() if count == ct_max]\n",
    "        \n",
    "        if len(majority_vote) == 1:\n",
    "            targets[display_id] = majority_vote[0]\n",
    "        else:  # different labels with same number of votes\n",
    "            mid_point = sum(majority_vote)/len(majority_vote)\n",
    "            if mid_point.is_integer():  # whole number\n",
    "                targets[display_id] = int(mid_point)\n",
    "            else:  # random selection\n",
    "                targets[display_id] = np.random.choice(majority_vote)\n",
    "                \n",
    "    return targets\n",
    "\n",
    "def create_splits(n):\n",
    "    sample_idx = np.arange(n)\n",
    "    np.random.shuffle(sample_idx)\n",
    "    \n",
    "    return (sample_idx[:int(n*0.8)], sample_idx[int(n*0.8):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Doc2Vec model\n",
      "vectorizing 2D data\n",
      "vectorizing 3D data\n"
     ]
    }
   ],
   "source": [
    "## sort using same index so video_metadate[i] matches video_transcriptions[i]\n",
    "video_metadata = video_metadata.sort_values(by=['display_id'])\n",
    "video_transcriptions = video_transcriptions.set_index('display_id')\n",
    "video_transcriptions = video_transcriptions.reindex(index=video_metadata['display_id'])\n",
    "video_transcriptions = video_transcriptions.reset_index()\n",
    "\n",
    "## create mappings\n",
    "video_idx_map = {display_id: i for i, display_id in enumerate(video_metadata['display_id'].values)}\n",
    "idx_video_map = {i: display_id for display_id, i in video_idx_map.items()}\n",
    "labeled_samples_ids = np.union1d(crowd_videos_uniq, expert_videos_uniq)\n",
    "labeled_samples_idx = [idx for video_id, idx in video_idx_map.items()\n",
    "                            if video_id in labeled_samples_ids]\n",
    "\n",
    "## vectorize text sequences\n",
    "data = np.hstack([video_metadata['fulltitle'].values,\n",
    "                  video_metadata['description'].values,\n",
    "                  video_metadata['tags'].values,\n",
    "                  video_transcriptions['clean_text'].values])\n",
    "\n",
    "print(\"training Doc2Vec model\")\n",
    "train_idx, test_idx = create_splits(data.shape[0])\n",
    "d2v_model = train_sequence_embeddings(data,\n",
    "                                      train_idx=train_idx, test_idx=test_idx,\n",
    "                                      vector_length=w2v_model.vector_size)\n",
    "\n",
    "data = data[labeled_samples_idx]  # we no longer need the unlabeled data\n",
    "data_length = max(map(len, data))  # maximum row length\n",
    "labeled_videos_idx_map = {idx_video_map[i]: j for j, i in enumerate(labeled_samples_idx)}\n",
    "idx_labeled_videos_map = {i: display_id for display_id, i in labeled_videos_idx_map.items()}\n",
    "\n",
    "print(\"vectorizing 2D data\")\n",
    "X_2D = vectorize_sequences2D(data,\n",
    "                             d2v_model,\n",
    "                             vector_length=w2v_model.vector_size)\n",
    "        \n",
    "print(\"vectorizing 3D data\")\n",
    "X_3D = vectorize_sequences3D(data,\n",
    "                             sequence_length=data_length,\n",
    "                             vector_length=w2v_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data.shape[0]\n",
    "assert num_samples == 120\n",
    "\n",
    "## generate labels - 7 point Likert scale\n",
    "y_likert_crowd = -np.ones(num_samples)\n",
    "for video_id, label in create_targets(crowd_videos_uniq, crowd_results).items():\n",
    "    y_likert_crowd[labeled_videos_idx_map[video_id]] = label - 1  # 0-based\n",
    "    \n",
    "y_likert_experts = -np.ones(num_samples)\n",
    "for video_id, label in create_targets(expert_videos_uniq, expert_results).items():\n",
    "    y_likert_experts[labeled_videos_idx_map[video_id]] = label - 1  # 0-based\n",
    "    \n",
    "## alternate labels - binary classification of framing type\n",
    "y_dominant_crowd = -np.ones(num_samples)\n",
    "for i in range(y_likert_crowd.shape[0]):\n",
    "    if y_likert_crowd[i] < 0:\n",
    "        continue\n",
    "    if y_likert_crowd[i] < 3:\n",
    "        y_dominant_crowd[i] = 0\n",
    "    elif y_likert_crowd[i] > 3:\n",
    "        y_dominant_crowd[i] = 1\n",
    "\n",
    "y_dominant_experts = -np.ones(num_samples)\n",
    "for i in range(y_likert_experts.shape[0]):\n",
    "    if y_likert_experts[i] < 0:\n",
    "        continue\n",
    "    if y_likert_experts[i] < 3:\n",
    "        y_dominant_experts[i] = 0\n",
    "    elif y_likert_experts[i] > 3:\n",
    "        y_dominant_experts[i] = 1\n",
    "        \n",
    "## combined set - no distinction between experts and crowd\n",
    "y_likert_combined = np.copy(y_likert_experts)  # expert labels are preferred\n",
    "copy_idx = np.where(y_likert_combined == -1)[0]\n",
    "y_likert_combined[copy_idx] = y_likert_crowd[copy_idx]\n",
    "\n",
    "y_dominant_combined = np.copy(y_dominant_experts)  # expert labels are preferred\n",
    "copy_idx = np.where(y_dominant_combined == -1)[0]\n",
    "y_dominant_combined[copy_idx] = y_dominant_crowd[copy_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(DATA_NPZ,\n",
    "                    X_2D = X_2D,\n",
    "                    X_3D = X_3D,\n",
    "                    y_likert_crowd = y_likert_crowd,\n",
    "                    y_likert_experts = y_likert_experts,\n",
    "                    y_dominant_crowd = y_dominant_crowd,\n",
    "                    y_dominant_experts = y_dominant_experts\n",
    "                    y_likert_combined = y_likert_combined,\n",
    "                    y_dominant_combined = y_dominant_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
