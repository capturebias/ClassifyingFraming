{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn\n",
    "#%pip install torch\n",
    "\n",
    "from math import sqrt\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "DATA_NPZ = DATA_DIR + \"data.npz\"\n",
    "\n",
    "## load files\n",
    "data = np.load(DATA_NPZ)\n",
    "\n",
    "X_2D = data['X_2D']\n",
    "X_3D = data['X_3D']\n",
    "y_likert_crowd = data['y_likert_crowd']\n",
    "y_likert_experts = data['y_likert_experts']\n",
    "y_dominant_crowd = data['y_dominant_crowd']\n",
    "y_dominant_experts = data['y_dominant_experts']\n",
    "y_likert_combined = data['y_likert_combined']\n",
    "y_dominant_combined = data['y_dominant_combined']\n",
    "\n",
    "\n",
    "# likert\n",
    "likert_expert_idx = np.where(y_likert_experts > -1)[0]\n",
    "likert_crowd_idx = np.where(y_likert_crowd > -1)[0]\n",
    "\n",
    "_likert_crowd_unique_idx = np.setdiff1d(likert_crowd_idx,\n",
    "                                likert_expert_idx,\n",
    "                                assume_unique=True)\n",
    "likert_combined_idx = np.concatenate([_likert_crowd_unique_idx,  # favour expert labels\n",
    "                                      likert_expert_idx])\n",
    "\n",
    "# dominant\n",
    "dominant_expert_idx = np.where(y_dominant_experts > -1)[0]\n",
    "dominant_crowd_idx = np.where(y_dominant_crowd > -1)[0]\n",
    "\n",
    "_dominant_crowd_unique_idx = np.setdiff1d(dominant_crowd_idx,\n",
    "                                  dominant_expert_idx,\n",
    "                                  assume_unique=True)\n",
    "dominant_combined_idx = np.concatenate([_dominant_crowd_unique_idx,\n",
    "                                        dominant_expert_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add signal to input data which tells the model from which set the labels are\n",
    "def add_bias_2D(args):\n",
    "    b = np.zeros((X_2D.shape[0], 1))\n",
    "    for idx, label in args:\n",
    "        b[idx] = label  # label = -1.0 | 1.0\n",
    "\n",
    "    return np.hstack([b, X_2D])\n",
    "\n",
    "def add_bias_3D(args):\n",
    "    b = np.zeros((X_3D.shape[0], 1, X_3D.shape[2]))\n",
    "    for idx, label in args:\n",
    "        b[idx, 0] = label  # label = -1.0 | 1.0\n",
    "    \n",
    "    return np.hstack([b.T, X_3D.T]).T\n",
    "\n",
    "X_2D_likert_expert_bias = add_bias_2D([(likert_expert_idx, 1.0)])\n",
    "X_2D_likert_crowd_bias = add_bias_2D([(likert_crowd_idx, -1.0)])\n",
    "X_2D_dominant_expert_bias = add_bias_2D([(dominant_expert_idx, 1.0)])\n",
    "X_2D_dominant_crowd_bias = add_bias_2D([(dominant_crowd_idx, -1.0)])\n",
    "X_2D_likert_combined_bias = add_bias_2D([(likert_combined_idx, 1.0), (_likert_crowd_unique_idx, -1.0)])\n",
    "X_2D_dominant_combined_bias = add_bias_2D([(dominant_combined_idx, 1.0), (_dominant_crowd_unique_idx, -1.0)])\n",
    "\n",
    "\n",
    "X_3D_likert_expert_bias = add_bias_3D([(likert_expert_idx, 1.0)])\n",
    "X_3D_likert_crowd_bias = add_bias_3D([(likert_crowd_idx, -1.0)])\n",
    "X_3D_dominant_expert_bias = add_bias_3D([(dominant_expert_idx, 1.0)])\n",
    "X_3D_dominant_crowd_bias = add_bias_3D([(dominant_crowd_idx, -1.0)])\n",
    "X_3D_likert_combined_bias = add_bias_3D([(likert_combined_idx, 1.0), (_likert_crowd_unique_idx, -1.0)])\n",
    "X_3D_dominant_combined_bias = add_bias_3D([(dominant_combined_idx, 1.0), (_dominant_crowd_unique_idx, -1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4187098763\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    return seed\n",
    "    \n",
    "print(set_seed())  # make reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(y, test_ratio=.5):\n",
    "    train_idx = list()\n",
    "    test_idx = list()\n",
    "    \n",
    "    strats = [np.where(y == lab)[0] for lab in np.unique(y) if lab > -1]\n",
    "    for strat in strats:\n",
    "        n = strat.shape[0]\n",
    "        train_idx.append(strat[:int(n*(1-test_ratio))])\n",
    "        test_idx.append(strat[int(n*(1-test_ratio)):])\n",
    "        \n",
    "    train_idx = np.concatenate(train_idx)\n",
    "    test_idx = np.concatenate(test_idx)\n",
    "    \n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(test_idx)\n",
    "    \n",
    "    return (train_idx, test_idx)\n",
    "\n",
    "def create_splits_one_hot(y):\n",
    "    vec = -np.ones(y.shape[0])\n",
    "    nonzero = y.nonzero()\n",
    "    vec[nonzero[:,0]] = nonzero[:,1].float()\n",
    "    \n",
    "    return create_splits(vec)\n",
    "\n",
    "def alpaydin_F_test(c1_acc_lst, c2_acc_lst):\n",
    "    # acc_list := [np.array([acc_ij, acc_i(j+1)]) for i in 5, j in 2]\n",
    "    assert len(c1_acc_lst) == len(c2_acc_lst)\n",
    "    diff_acc_lst = [c1_acc_lst[i] - c2_acc_lst[i] for i in range(len(c1_acc_lst))]\n",
    "    \n",
    "    mean_lst = [np.mean(a) for a in diff_acc_lst] \n",
    "    var_lst = [ (diff_acc_lst[i][0] - mean_lst[i])**2\n",
    "               +(diff_acc_lst[i][1] - mean_lst[i])**2 for i in range(len(diff_acc_lst))]\n",
    "    \n",
    "    numerator = sum([sum(a**2) for a in diff_acc_lst])\n",
    "    denumerator = 2 * sum(var_lst)\n",
    "    f = numerator / denumerator\n",
    "    p_value = stats.f.sf(f, 10, 5)\n",
    "    \n",
    "    return (f, p_value, np.mean(mean_lst), np.mean(var_lst))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure same datasets per model\n",
    "likert_crowd_splits = [create_splits(y_likert_crowd[likert_crowd_idx]) for i in range(5)]\n",
    "likert_expert_splits = [create_splits(y_likert_experts[likert_expert_idx]) for i in range(5)]\n",
    "likert_combined_splits = [create_splits(y_likert_combined[likert_combined_idx]) for i in range(5)]\n",
    "\n",
    "dominant_crowd_splits = [create_splits(y_dominant_crowd[dominant_crowd_idx]) for i in range(5)]\n",
    "dominant_expert_splits = [create_splits(y_dominant_experts[dominant_expert_idx]) for i in range(5)]\n",
    "dominant_combined_splits = [create_splits(y_dominant_combined[dominant_combined_idx]) for i in range(5)]\n",
    "\n",
    "labels = ['expert_likert', 'crowd_likert', 'combined_likert',\n",
    "          'expert_dominant', 'crowd_dominant', 'combined_dominant']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_class(y):\n",
    "    ct = Counter(y)\n",
    "    return ct.most_common(1)[0][1] / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class accuracy on Likert labels (baseline)\n",
      " crowd labels:  0.2437\n",
      " expert labels: 0.2241\n",
      " combined labels: 0.2521\n",
      "\n",
      "Majority class accuracy on Dominant labels (baseline)\n",
      " crowd labels:  0.5400\n",
      " expert labels: 0.6383\n",
      " combined labels: 0.5766\n"
     ]
    }
   ],
   "source": [
    "majority_class_acc_crowd_likert = majority_class(y_likert_crowd[likert_crowd_idx])\n",
    "majority_class_acc_experts_likert = majority_class(y_likert_experts[likert_expert_idx])\n",
    "majority_class_acc_combined_likert = majority_class(y_likert_combined[likert_combined_idx])\n",
    "\n",
    "print(\"Majority class accuracy on Likert labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_likert))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_likert))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_likert))\n",
    "\n",
    "majority_class_acc_crowd_dominant = majority_class(y_dominant_crowd[dominant_crowd_idx])\n",
    "majority_class_acc_experts_dominant = majority_class(y_dominant_experts[dominant_expert_idx])\n",
    "majority_class_acc_combined_dominant = majority_class(y_dominant_combined[dominant_combined_idx])\n",
    "\n",
    "print(\"\\nMajority class accuracy on Dominant labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_dominant))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_dominant))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_dominant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (supervised)\n",
    "\n",
    "We start with a traditional, or 'shallow', machine learning model: random forest. Because random forest does not support iterative learning, we test both the crowd and expert sets separately.\n",
    "\n",
    "We use stratified cross validation to reduce the effects caused by the small size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = [100, 250, 500, 750, 1000, 2000]\n",
    "\n",
    "def random_forest(X, y, index, splits, n_estimators=N_ESTIMATORS):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_est_lst = list()\n",
    "    for n_estimators in N_ESTIMATORS:\n",
    "        print(\"Training with {} estimators\".format(n_estimators))\n",
    "        acc_lst = list()\n",
    "        for fold_i in range(5):\n",
    "            print(\" Starting outer fold {} / {}\".format(fold_i+1, 5))\n",
    "            acc_inner = list()\n",
    "            split_a_idx, split_b_idx  = splits[fold_i]\n",
    "            for fold_j in range(2):\n",
    "                print(\"  Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "                if fold_j % 2 == 0:\n",
    "                    train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "                else:\n",
    "                    train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "\n",
    "                train_idx = index[train_fold_idx]\n",
    "                test_idx = index[test_fold_idx]\n",
    "\n",
    "                model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_pred = model.predict(X[test_idx])\n",
    "                fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "\n",
    "                acc_inner.append(fold_acc)\n",
    "                print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "\n",
    "            acc_lst.append(np.array(acc_inner))\n",
    "        print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "        acc_est_lst.append(acc_lst)\n",
    "    \n",
    "    return acc_est_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.0938)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1538)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.1882\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2161\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1538)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1798\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1538)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2077\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1538)\n",
      " => mean acc: 0.2046\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2500)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.460709</td>\n",
       "      <td>0.287369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.347415</td>\n",
       "      <td>0.644050</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.318804</td>\n",
       "      <td>0.684134</td>\n",
       "      <td>0.219655</td>\n",
       "      <td>0.476727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.439135</td>\n",
       "      <td>0.702782</td>\n",
       "      <td>0.252272</td>\n",
       "      <td>0.647048</td>\n",
       "      <td>0.76681</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750     1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN      NaN   NaN\n",
       "1       250  0.009518       NaN       NaN       NaN      NaN   NaN\n",
       "2       500  0.460709  0.287369       NaN       NaN      NaN   NaN\n",
       "3       750  0.347415  0.644050  0.534881       NaN      NaN   NaN\n",
       "4      1000  0.318804  0.684134  0.219655  0.476727      NaN   NaN\n",
       "5      2000  0.439135  0.702782  0.252272  0.647048  0.76681   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "random_forest_acc_experts_likert = random_forest(X_2D_likert_expert_bias,\n",
    "                                                 y_likert_experts, \n",
    "                                                 likert_expert_idx,\n",
    "                                                 likert_expert_splits)\n",
    "\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_experts_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_experts_likert[i],\n",
    "                                               random_forest_acc_experts_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " => mean acc: 0.1978\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2258)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " => mean acc: 0.2130\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " => mean acc: 0.2027\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " => mean acc: 0.2074\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " => mean acc: 0.2076\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " => mean acc: 0.2074\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.369726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.451041</td>\n",
       "      <td>0.291856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.620907</td>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.136848</td>\n",
       "      <td>0.478471</td>\n",
       "      <td>0.407105</td>\n",
       "      <td>0.656842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.584182</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.479906</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.447021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.369726       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.451041  0.291856       NaN       NaN       NaN   NaN\n",
       "3       750  0.620907  0.484985  0.576704       NaN       NaN   NaN\n",
       "4      1000  0.136848  0.478471  0.407105  0.656842       NaN   NaN\n",
       "5      2000  0.584182  0.534881  0.479906  0.534881  0.447021   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "random_forest_acc_crowd_likert = random_forest(X_2D_likert_crowd_bias,\n",
    "                                               y_likert_crowd,\n",
    "                                               likert_crowd_idx,\n",
    "                                               likert_crowd_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_crowd_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_crowd_likert[i],\n",
    "                                               random_forest_acc_crowd_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.0645)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " => mean acc: 0.1417\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " => mean acc: 0.1347\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " => mean acc: 0.1498\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1416\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " => mean acc: 0.1400\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1482\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.592102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.222193</td>\n",
       "      <td>0.308721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.628285</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.389524</td>\n",
       "      <td>0.214384</td>\n",
       "      <td>0.381913</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.194827</td>\n",
       "      <td>0.255459</td>\n",
       "      <td>0.406362</td>\n",
       "      <td>0.318461</td>\n",
       "      <td>0.165202</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.592102       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.222193  0.308721       NaN       NaN       NaN   NaN\n",
       "3       750  0.010821  0.628285  0.534881       NaN       NaN   NaN\n",
       "4      1000  0.389524  0.214384  0.381913  0.823267       NaN   NaN\n",
       "5      2000  0.194827  0.255459  0.406362  0.318461  0.165202   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "random_forest_acc_combined_likert = random_forest(X_2D_likert_combined_bias,\n",
    "                                                  y_likert_combined,\n",
    "                                                  likert_combined_idx,\n",
    "                                                  likert_combined_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_combined_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_combined_likert[i],\n",
    "                                               random_forest_acc_combined_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6087)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " => mean acc: 0.6013\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6138\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " => mean acc: 0.6179\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6264\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6221\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6053\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.323699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.407975</td>\n",
       "      <td>0.687706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.263998</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.451352</td>\n",
       "      <td>0.772292</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.300760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.263998</td>\n",
       "      <td>0.646934</td>\n",
       "      <td>0.699595</td>\n",
       "      <td>0.108841</td>\n",
       "      <td>0.222823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.323699       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.407975  0.687706       NaN       NaN       NaN   NaN\n",
       "3       750  0.171813  0.263998  0.534881       NaN       NaN   NaN\n",
       "4      1000  0.451352  0.772292  0.534881  0.300760       NaN   NaN\n",
       "5      2000  0.263998  0.646934  0.699595  0.108841  0.222823   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "random_forest_acc_experts_dominant = random_forest(X_2D_dominant_expert_bias,\n",
    "                                                   y_dominant_experts, \n",
    "                                                   dominant_expert_idx,\n",
    "                                                   dominant_expert_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_experts_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_experts_dominant[i],\n",
    "                                               random_forest_acc_experts_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5200)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5200)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4000)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5600)\n",
      " => mean acc: 0.4680\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5200)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " => mean acc: 0.4520\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " => mean acc: 0.4460\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " => mean acc: 0.4400\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " => mean acc: 0.4300\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " => mean acc: 0.4240\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.482836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.226023</td>\n",
       "      <td>0.429627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.486235</td>\n",
       "      <td>0.414563</td>\n",
       "      <td>0.463102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.240830</td>\n",
       "      <td>0.271786</td>\n",
       "      <td>0.268087</td>\n",
       "      <td>0.401629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.074656</td>\n",
       "      <td>0.201367</td>\n",
       "      <td>0.169724</td>\n",
       "      <td>0.466787</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.482836       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.226023  0.429627       NaN       NaN       NaN   NaN\n",
       "3       750  0.486235  0.414563  0.463102       NaN       NaN   NaN\n",
       "4      1000  0.240830  0.271786  0.268087  0.401629       NaN   NaN\n",
       "5      2000  0.074656  0.201367  0.169724  0.466787  0.534881   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "random_forest_acc_crowd_dominant = random_forest(X_2D_dominant_crowd_bias,\n",
    "                                                 y_dominant_crowd,\n",
    "                                                 dominant_crowd_idx,\n",
    "                                                 dominant_crowd_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_crowd_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_crowd_dominant[i],\n",
    "                                               random_forest_acc_crowd_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4107)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5273)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5091)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5455)\n",
      " => mean acc: 0.4920\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5455)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " => mean acc: 0.4812\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " => mean acc: 0.4865\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5091)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " => mean acc: 0.4883\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4464)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " => mean acc: 0.4740\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " => mean acc: 0.4793\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.254150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.696442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.070223</td>\n",
       "      <td>0.495411</td>\n",
       "      <td>0.410572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.609916</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.107392</td>\n",
       "      <td>0.656040</td>\n",
       "      <td>0.296335</td>\n",
       "      <td>0.403768</td>\n",
       "      <td>0.657462</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.254150       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.050211  0.696442       NaN       NaN       NaN   NaN\n",
       "3       750  0.070223  0.495411  0.410572       NaN       NaN   NaN\n",
       "4      1000  0.017025  0.609916  0.534881  0.534881       NaN   NaN\n",
       "5      2000  0.107392  0.656040  0.296335  0.403768  0.657462   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "random_forest_acc_combined_dominant = random_forest(X_2D_dominant_combined_bias,\n",
    "                                                    y_dominant_combined,\n",
    "                                                    dominant_combined_idx,\n",
    "                                                    dominant_combined_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_combined_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_combined_dominant[i],\n",
    "                                               random_forest_acc_combined_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "def pac(X, y, index, splits):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_lst = list()\n",
    "    for fold_i in range(5):\n",
    "        print(\" Starting outer fold {} / {}\".format(fold_i+1, 5), end='')\n",
    "        acc_inner = list()\n",
    "        split_a_idx, split_b_idx  = splits[fold_i]\n",
    "        for fold_j in range(2):\n",
    "            print(\"  Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "            if fold_j % 2 == 0:\n",
    "                train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "            else:\n",
    "                train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "\n",
    "            train_idx = index[train_fold_idx]\n",
    "            test_idx = index[test_fold_idx]\n",
    "\n",
    "            model = PassiveAggressiveClassifier(max_iter=2000, warm_start=False)\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    " \n",
    "            y_pred = model.predict(X[test_idx])\n",
    "            fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "\n",
    "            acc_inner.append(fold_acc)\n",
    "            print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "            \n",
    "        acc_lst.append(np.array(acc_inner))\n",
    "    print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "    \n",
    "    return acc_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1899\n",
      "\n",
      "=== Results of supervised learning on crowd likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.2258)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " => mean acc: 0.1671\n",
      "\n",
      "=== Results of supervised learning on combined likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1584\n",
      "\n",
      "=== Results of supervised learning on expert dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5217)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4348)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4348)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " => mean acc: 0.5639\n",
      "\n",
      "=== Results of supervised learning on crowd dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.5200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " => mean acc: 0.4800\n",
      "\n",
      "=== Results of supervised learning on combined dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4000)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.4464)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.5357)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4182)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5273)\n",
      " => mean acc: 0.4701\n",
      "\n",
      "= p-values =\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>0.470623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.582789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>0.017327</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.017271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.609718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.372802</td>\n",
       "      <td>0.646651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values  expert_likert  crowd_likert  combined_likert  \\\n",
       "0      expert_likert            NaN           NaN              NaN   \n",
       "1       crowd_likert       0.470623           NaN              NaN   \n",
       "2    combined_likert       0.052602      0.582789              NaN   \n",
       "3    expert_dominant       0.017327      0.004232         0.017271   \n",
       "4     crowd_dominant       0.000041      0.000347         0.000030   \n",
       "5  combined_dominant       0.000699      0.000368         0.000815   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3              NaN             NaN                NaN  \n",
       "4         0.609718             NaN                NaN  \n",
       "5         0.372802        0.646651                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "pac_acc_experts_likert = pac(X_2D_likert_expert_bias,\n",
    "                                y_likert_experts, \n",
    "                                likert_expert_idx,\n",
    "                                likert_expert_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "pac_acc_crowd_likert = pac(X_2D_likert_crowd_bias,\n",
    "                              y_likert_crowd,\n",
    "                              likert_crowd_idx,\n",
    "                              likert_crowd_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "pac_acc_combined_likert = pac(X_2D_dominant_combined_bias,\n",
    "                                 y_likert_combined,\n",
    "                                 likert_combined_idx,\n",
    "                                 likert_combined_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "pac_acc_experts_dominant = pac(X_2D_dominant_expert_bias,\n",
    "                                  y_dominant_experts, \n",
    "                                  dominant_expert_idx,\n",
    "                                  dominant_expert_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "pac_acc_crowd_dominant = pac(X_2D_dominant_crowd_bias,\n",
    "                                y_dominant_crowd,\n",
    "                                dominant_crowd_idx,\n",
    "                                dominant_crowd_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "pac_acc_combined_dominant = pac(X_2D_dominant_combined_bias,\n",
    "                                   y_dominant_combined,\n",
    "                                   dominant_combined_idx,\n",
    "                                   dominant_combined_splits)\n",
    "\n",
    "pac_acc = [pac_acc_experts_likert, pac_acc_crowd_likert, pac_acc_combined_likert,\n",
    "           pac_acc_experts_dominant, pac_acc_crowd_dominant, pac_acc_combined_dominant]\n",
    "\n",
    "print(\"= p-values =\")\n",
    "table = {'p-values': labels}\n",
    "table.update({lab: list() for lab in labels})\n",
    "nlabels = len(labels)\n",
    "for i in range(nlabels):\n",
    "    for e in range(i+1):\n",
    "        table[labels[i]].append(np.nan)\n",
    "    for j in range(i+1, nlabels):\n",
    "        f, p, mean, variance = alpaydin_F_test(pac_acc[i],\n",
    "                                               pac_acc[j])\n",
    "        table[labels[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(pac_acc[i], pac_acc[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incremental learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert numpy arrays to PyTorch tensors\n",
    "X_2D_likert_crowd_bias = torch.from_numpy(X_2D_likert_crowd_bias)\n",
    "X_2D_likert_expert_bias = torch.from_numpy(X_2D_likert_expert_bias)\n",
    "X_2D_likert_combined_bias = torch.from_numpy(X_2D_likert_combined_bias)\n",
    "X_2D_dominant_crowd_bias = torch.from_numpy(X_2D_dominant_crowd_bias)\n",
    "X_2D_dominant_expert_bias = torch.from_numpy(X_2D_dominant_expert_bias)\n",
    "X_2D_dominant_combined_bias = torch.from_numpy(X_2D_dominant_combined_bias)\n",
    "\n",
    "X_3D_likert_crowd_bias = torch.from_numpy(X_3D_likert_crowd_bias)\n",
    "X_3D_likert_expert_bias = torch.from_numpy(X_3D_likert_expert_bias)\n",
    "X_3D_likert_combined_bias = torch.from_numpy(X_3D_likert_combined_bias)\n",
    "X_3D_dominant_crowd_bias = torch.from_numpy(X_3D_dominant_crowd_bias)\n",
    "X_3D_dominant_expert_bias = torch.from_numpy(X_3D_dominant_expert_bias)\n",
    "X_3D_dominant_combined_bias = torch.from_numpy(X_3D_dominant_combined_bias)\n",
    "\n",
    "y_likert_crowd = torch.from_numpy(y_likert_crowd)\n",
    "y_likert_experts = torch.from_numpy(y_likert_experts)\n",
    "y_likert_combined = torch.from_numpy(y_likert_combined)\n",
    "y_dominant_crowd = torch.from_numpy(y_dominant_crowd)\n",
    "y_dominant_experts = torch.from_numpy(y_dominant_experts)\n",
    "y_dominant_combined = torch.from_numpy(y_dominant_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(y_hat, y):\n",
    "    # y := 1D array of class labels\n",
    "    # y_hat := 2D array of one-hot class labels\n",
    "    _, labels = y_hat.max(dim=1)\n",
    "    return torch.mean(torch.eq(labels, y).float())\n",
    "\n",
    "def fit(model, X, y, index, splits, lr=0.01, l2norm=0.01, n_epoch=250, patience=-1):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_lst = list()\n",
    "    for fold_i in range(5):\n",
    "        print(\"Starting outer fold {} / {}\".format(fold_i+1, 5))\n",
    "        acc_inner = list()\n",
    "        split_a_idx, split_b_idx  = splits[fold_i]\n",
    "\n",
    "        for fold_j in range(2):\n",
    "            print(\" Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "            if fold_j % 2 == 0:\n",
    "                train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "            else:\n",
    "                train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "                \n",
    "            train_idx = index[train_fold_idx]\n",
    "            test_idx = index[test_fold_idx]\n",
    "            \n",
    "            model.init()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            # early stopping\n",
    "            patience_left = patience\n",
    "            best_fold_score = -1\n",
    "            delta = 1e-4\n",
    "            best_fold_state = None\n",
    "            best_fold_state_opt = None\n",
    "        \n",
    "            for epoch in range(n_epoch):\n",
    "                model.train()\n",
    "\n",
    "                y_hat = model(X[train_idx].float())\n",
    "                train_acc = categorical_accuracy(y_hat, y[train_idx])\n",
    "                train_loss = criterion(y_hat, y[train_idx].long())\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                test_loss = None\n",
    "                with torch.no_grad():\n",
    "                    y_hat = model(X[test_idx].float())\n",
    "                    test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "                    test_loss = criterion(y_hat, y[test_idx].long())\n",
    "\n",
    "                train_loss = float(train_loss.item())\n",
    "                test_loss = float(test_loss.item())\n",
    "                \n",
    "                if best_fold_score < 0:\n",
    "                    best_fold_score = test_loss\n",
    "                    best_fold_state = model.state_dict()\n",
    "                    best_fold_state_opt = optimizer.state_dict()\n",
    "\n",
    "                if patience <= 0:\n",
    "                    continue\n",
    "                if test_loss >= best_fold_score - delta:\n",
    "                    patience_left -= 1\n",
    "                else:\n",
    "                    best_fold_score = test_loss\n",
    "                    best_fold_state = model.state_dict()\n",
    "                    best_fold_state_opt = optimizer.state_dict()\n",
    "                    patience_left = patience\n",
    "                if patience_left <= 0:\n",
    "                    model.load_state_dict(best_fold_state)\n",
    "                    optimizer.load_state_dict(best_fold_state_opt)\n",
    "                    break\n",
    "            \n",
    "            # do a final run over the test set after loading a previous state\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(X[test_idx].float())\n",
    "                test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "                test_loss = criterion(y_hat, y[test_idx].long())\n",
    "            \n",
    "            test_loss = float(test_loss.item())\n",
    "            print(\" (acc: {:.4f})\".format(test_acc))\n",
    "            acc_inner.append(test_acc)\n",
    "    \n",
    "        acc_lst.append(np.array(acc_inner))\n",
    "        \n",
    "    print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "\n",
    "    return acc_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNN(nn.Module):\n",
    "    \"\"\"Simple Neural Network Classifier\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, p_dropout=0.05):\n",
    "        super().__init__()\n",
    "        hidden_dim = (input_dim-output_dim)//2\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(input_dim, hidden_dim),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(p=p_dropout)))\n",
    "            \n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(hidden_dim, output_dim),\n",
    "                            nn.ReLU(inplace=True)))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)                          \n",
    "                           \n",
    "        return self.softmax(X)\n",
    "        \n",
    "    def init(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1250)\n",
      " Starting inner fold 2 / 2 (acc: 0.2308)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1250)\n",
      " Starting inner fold 2 / 2 (acc: 0.1538)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.0625)\n",
      " Starting inner fold 2 / 2 (acc: 0.2692)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.0938)\n",
      " Starting inner fold 2 / 2 (acc: 0.2308)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1562)\n",
      " Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1639\n",
      "\n",
      "\n",
      "=== Results on crowd likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1613)\n",
      " Starting inner fold 2 / 2 (acc: 0.1579)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1613)\n",
      " Starting inner fold 2 / 2 (acc: 0.2281)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1452)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1613)\n",
      " Starting inner fold 2 / 2 (acc: 0.1754)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1613)\n",
      " Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " => mean acc: 0.1650\n",
      "\n",
      "\n",
      "=== Results on combined likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1613)\n",
      " Starting inner fold 2 / 2 (acc: 0.1579)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.2581)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1935)\n",
      " Starting inner fold 2 / 2 (acc: 0.0877)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1129)\n",
      " Starting inner fold 2 / 2 (acc: 0.2105)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1129)\n",
      " Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " => mean acc: 0.1576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_2D_likert_combined_bias.shape[1]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert likert labels ===\")\n",
    "neural_net_acc_likert_experts = fit(model, X_2D_likert_expert_bias, y_likert_experts, likert_expert_idx, likert_expert_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd likert labels ===\")\n",
    "neural_net_acc_likert_crowd = fit(model, X_2D_likert_crowd_bias, y_likert_crowd, likert_crowd_idx, likert_crowd_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined likert labels ===\")\n",
    "neural_net_acc_likert_combined = fit(model, X_2D_likert_combined_bias, y_likert_combined, likert_combined_idx, likert_combined_splits, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5417)\n",
      " Starting inner fold 2 / 2 (acc: 0.4783)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5417)\n",
      " Starting inner fold 2 / 2 (acc: 0.5217)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.6250)\n",
      " Starting inner fold 2 / 2 (acc: 0.5217)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5417)\n",
      " Starting inner fold 2 / 2 (acc: 0.5652)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5417)\n",
      " Starting inner fold 2 / 2 (acc: 0.5217)\n",
      " => mean acc: 0.5400\n",
      "\n",
      "\n",
      "=== Results on crowd dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5600)\n",
      " Starting inner fold 2 / 2 (acc: 0.4400)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4200)\n",
      " Starting inner fold 2 / 2 (acc: 0.4600)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4200)\n",
      " Starting inner fold 2 / 2 (acc: 0.4800)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4800)\n",
      " Starting inner fold 2 / 2 (acc: 0.5000)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4800)\n",
      " Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " => mean acc: 0.4660\n",
      "\n",
      "\n",
      "=== Results on combined dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5000)\n",
      " Starting inner fold 2 / 2 (acc: 0.4182)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4821)\n",
      " Starting inner fold 2 / 2 (acc: 0.4727)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4821)\n",
      " Starting inner fold 2 / 2 (acc: 0.4727)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4286)\n",
      " Starting inner fold 2 / 2 (acc: 0.5818)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5536)\n",
      " Starting inner fold 2 / 2 (acc: 0.6000)\n",
      " => mean acc: 0.4992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.1\n",
    "\n",
    "## define model\n",
    "indim = X_2D_dominant_combined_bias.shape[1]\n",
    "outdim = np.unique(y_dominant_experts[dominant_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_dominant_crowd[dominant_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "neural_net_acc_dominant_experts = fit(model, X_2D_dominant_expert_bias, y_dominant_experts, dominant_expert_idx, dominant_expert_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "neural_net_acc_dominant_crowd = fit(model, X_2D_dominant_crowd_bias, y_dominant_crowd, dominant_crowd_idx, dominant_crowd_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined dominant labels ===\")\n",
    "neural_net_acc_dominant_combined = fit(model, X_2D_dominant_combined_bias, y_dominant_combined, dominant_combined_idx, dominant_combined_splits, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= p-values =\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>0.761043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>0.802733</td>\n",
       "      <td>0.802535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.165788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.278232</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values  expert_likert  crowd_likert  combined_likert  \\\n",
       "0      expert_likert            NaN           NaN              NaN   \n",
       "1       crowd_likert       0.761043           NaN              NaN   \n",
       "2    combined_likert       0.802733      0.802535              NaN   \n",
       "3    expert_dominant       0.009186      0.000070         0.000298   \n",
       "4     crowd_dominant       0.009907      0.000866         0.009762   \n",
       "5  combined_dominant       0.004603      0.000515         0.000724   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3              NaN             NaN                NaN  \n",
       "4         0.165788             NaN                NaN  \n",
       "5         0.278232        0.324219                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_acc = [neural_net_acc_likert_experts, neural_net_acc_likert_crowd, neural_net_acc_likert_combined,\n",
    "          neural_net_acc_dominant_experts, neural_net_acc_dominant_crowd, neural_net_acc_dominant_combined]\n",
    "\n",
    "print(\"= p-values =\")\n",
    "table = {'p-values': labels}\n",
    "table.update({lab: list() for lab in labels})\n",
    "nlabels = len(labels)\n",
    "for i in range(nlabels):\n",
    "    for e in range(i+1):\n",
    "        table[labels[i]].append(np.nan)\n",
    "    for j in range(i+1, nlabels):\n",
    "        f, p, mean, variance = alpaydin_F_test(nn_acc[i],\n",
    "                                               nn_acc[j])\n",
    "        table[labels[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(nn_acc[i], nn_acc[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 100 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.360185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.702479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 100 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.001755           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000021              NaN   \n",
       "2           combined_likert            NaN           NaN         0.002268   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.374312             NaN                NaN  \n",
       "4              NaN        0.360185                NaN  \n",
       "5              NaN             NaN           0.702479  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 250 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 250 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.001774           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000176              NaN   \n",
       "2           combined_likert            NaN           NaN         0.000826   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.234739             NaN                NaN  \n",
       "4              NaN        0.648495                NaN  \n",
       "5              NaN             NaN            0.23877  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 500 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.602719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 500 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.003497           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000016              NaN   \n",
       "2           combined_likert            NaN           NaN         0.002808   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.232779             NaN                NaN  \n",
       "4              NaN        0.602719                NaN  \n",
       "5              NaN             NaN           0.517162  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 750 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 750 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.003551           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000005              NaN   \n",
       "2           combined_likert            NaN           NaN         0.001721   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.170302             NaN                NaN  \n",
       "4              NaN        0.503998                NaN  \n",
       "5              NaN             NaN           0.281369  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 1000 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 1000 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0              expert_likert       0.002145           NaN              NaN   \n",
       "1               crowd_likert            NaN      0.000087              NaN   \n",
       "2            combined_likert            NaN           NaN         0.001762   \n",
       "3            expert_dominant            NaN           NaN              NaN   \n",
       "4             crowd_dominant            NaN           NaN              NaN   \n",
       "5          combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.213384             NaN                NaN  \n",
       "4              NaN        0.701554                NaN  \n",
       "5              NaN             NaN           0.435686  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 2000 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 2000 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0              expert_likert       0.004477           NaN              NaN   \n",
       "1               crowd_likert            NaN      0.000035              NaN   \n",
       "2            combined_likert            NaN           NaN         0.001609   \n",
       "3            expert_dominant            NaN           NaN              NaN   \n",
       "4             crowd_dominant            NaN           NaN              NaN   \n",
       "5          combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.158725             NaN                NaN  \n",
       "4              NaN        0.595507                NaN  \n",
       "5              NaN             NaN           0.534881  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_acc = [random_forest_acc_experts_likert, random_forest_acc_crowd_likert, random_forest_acc_combined_likert,\n",
    "           random_forest_acc_experts_dominant, random_forest_acc_crowd_dominant, random_forest_acc_combined_dominant]\n",
    "\n",
    "nhypotheses = len(N_ESTIMATORS)\n",
    "for k in range(nhypotheses):\n",
    "    table = {'p-values - {} estimators'.format(N_ESTIMATORS[k]): labels}\n",
    "    table.update({lab: list() for lab in labels})\n",
    "\n",
    "    nlabels = len(labels)\n",
    "    for i in range(nlabels):\n",
    "        for e in range(nlabels):\n",
    "            if e != i:\n",
    "                table[labels[i]].append(np.nan)\n",
    "            else:\n",
    "                f, p, mean, variance = alpaydin_F_test(nn_acc[i],\n",
    "                                                       rf_acc[j][k])\n",
    "                table[labels[i]].append(p)\n",
    "                #print(\"RF {} vs {} estimators\".format(nn_acc[i], nn_acc[j]))\n",
    "                #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "    significance = pd.DataFrame(table)\n",
    "    display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
