{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xander/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/xander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## prequisites\n",
    "#%pip install pandas\n",
    "#%pip install numpy\n",
    "#%pip install nltk\n",
    "\n",
    "## libraries\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "VIDEO_METADATA = DATA_DIR + \"2014_metadata.csv\"\n",
    "VIDEO_TRANSCRIPTIONS = DATA_DIR + \"2014_transcripts_months_1to4.csv\"\n",
    "DATA_NPZ = DATA_DIR + \"sequences_preprocessed.npz\"\n",
    "\n",
    "## load files\n",
    "video_metadata = pd.read_csv(VIDEO_METADATA, delimiter=';')\n",
    "video_transcriptions = pd.read_csv(VIDEO_TRANSCRIPTIONS)\n",
    "\n",
    "## download wordnet vocabulary used in preprocessing the transcriptions\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess sequences\n",
    "stemmer = WordNetLemmatizer()\n",
    "def prep_text(s):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', s)\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    doc_length = len(document)\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join([word for word in document if word not in stops])\n",
    "    \n",
    "    return (document, doc_length)\n",
    "\n",
    "## drop duplicates\n",
    "video_transcriptions = video_transcriptions.drop_duplicates(subset='display_id', keep='last')\n",
    "video_metadata = video_metadata.drop_duplicates(subset='display_id', keep='last')\n",
    "\n",
    "## remove rows with missing transcriptions\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['clean_text'].notna()]\n",
    "\n",
    "## remove meta data entries that we don't have transcriptions for\n",
    "video_ids = np.intersect1d(video_metadata['display_id'].values, video_transcriptions['display_id'].values)\n",
    "video_metadata = video_metadata[video_metadata['display_id'].isin(video_ids)]\n",
    "video_transcriptions = video_transcriptions[video_transcriptions['display_id'].isin(video_ids)]\n",
    "\n",
    "assert(len(video_metadata) == len(video_transcriptions))\n",
    "\n",
    "## process text\n",
    "for index, row in video_transcriptions.iterrows():\n",
    "    text = row['clean_text']\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_transcriptions.loc[index, 'clean_text'] = text_processed\n",
    "  \n",
    "for index, row in video_metadata.iterrows():\n",
    "    for label in ['fulltitle', 'description']:\n",
    "        text = row[label]\n",
    "        text_processed, nwords = prep_text(text)\n",
    "        video_metadata.loc[index, label] = text_processed\n",
    "\n",
    "    text = ' '.join([tag for tag in row['tags'].split('+')])\n",
    "    text_processed, nwords = prep_text(text)\n",
    "    video_metadata.loc[index, 'tags'] = text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdata_list(*args):\n",
    "    data = [list() for i in range(args[0].shape[0])]\n",
    "    for a in args:\n",
    "        for i, row in enumerate(a):\n",
    "            if len(row) <= 0:\n",
    "                continue\n",
    "\n",
    "            data[i].extend(row.split())\n",
    "                \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort using same index so video_metadate[i] matches video_transcriptions[i]\n",
    "video_metadata = video_metadata.sort_values(by=['display_id'])\n",
    "video_transcriptions = video_transcriptions.set_index('display_id')\n",
    "video_transcriptions = video_transcriptions.reindex(index=video_metadata['display_id'])\n",
    "video_transcriptions = video_transcriptions.reset_index()\n",
    "\n",
    "## mapping display_id to index\n",
    "video_idx = video_metadata['display_id'].values\n",
    "\n",
    "## create mappings\n",
    "video_idx_map = {display_id: i for i, display_id in enumerate(video_metadata['display_id'].values)}\n",
    "idx_video_map = {i: display_id for display_id, i in video_idx_map.items()}\n",
    "\n",
    "## create dataset\n",
    "data = mkdata_list(video_metadata['fulltitle'].values,\n",
    "                   video_metadata['description'].values,\n",
    "                   video_metadata['tags'].values,\n",
    "                   video_transcriptions['clean_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(DATA_NPZ, sequences=data, video_idx=video_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
