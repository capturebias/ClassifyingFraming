{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn\n",
    "#%pip install torch\n",
    "\n",
    "from math import sqrt\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "DATA_NPZ = DATA_DIR + \"data.npz\"\n",
    "\n",
    "## load files\n",
    "data = np.load(DATA_NPZ)\n",
    "\n",
    "X_2D = data['X_2D']\n",
    "X_3D = data['X_3D']\n",
    "y_likert_crowd = data['y_likert_crowd']\n",
    "y_likert_experts = data['y_likert_experts']\n",
    "y_dominant_crowd = data['y_dominant_crowd']\n",
    "y_dominant_experts = data['y_dominant_experts']\n",
    "y_likert_combined = data['y_likert_combined']\n",
    "y_dominant_combined = data['y_dominant_combined']\n",
    "\n",
    "\n",
    "# likert\n",
    "likert_expert_idx = np.where(y_likert_experts > -1)[0]\n",
    "likert_crowd_idx = np.where(y_likert_crowd > -1)[0]\n",
    "\n",
    "_likert_crowd_unique_idx = np.setdiff1d(np.where(y_likert_crowd > -1)[0],\n",
    "                                likert_expert_idx,\n",
    "                                assume_unique=True)\n",
    "likert_combined_idx = np.concatenate([_likert_crowd_unique_idx,\n",
    "                                      likert_expert_idx])\n",
    "\n",
    "# dominant\n",
    "dominant_expert_idx = np.where(y_dominant_experts > -1)[0]\n",
    "dominant_crowd_idx = np.where(y_dominant_crowd > -1)[0]\n",
    "\n",
    "_dominant_crowd_unique_idx = np.setdiff1d(np.where(y_dominant_crowd > -1)[0],\n",
    "                                  dominant_expert_idx,\n",
    "                                  assume_unique=True)\n",
    "dominant_combined_idx = np.concatenate([_dominant_crowd_unique_idx,\n",
    "                                        dominant_expert_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205365004\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    return seed\n",
    "    \n",
    "print(set_seed())  # make reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(y, test_ratio=.5):\n",
    "    train_idx = list()\n",
    "    test_idx = list()\n",
    "    \n",
    "    strats = [np.where(y == lab)[0] for lab in np.unique(y) if lab > -1]\n",
    "    for strat in strats:\n",
    "        n = strat.shape[0]\n",
    "        train_idx.append(strat[:int(n*(1-test_ratio))])\n",
    "        test_idx.append(strat[int(n*(1-test_ratio)):])\n",
    "        \n",
    "    train_idx = np.concatenate(train_idx)\n",
    "    test_idx = np.concatenate(test_idx)\n",
    "    \n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(test_idx)\n",
    "    \n",
    "    return (train_idx, test_idx)\n",
    "\n",
    "def create_splits_one_hot(y):\n",
    "    vec = -np.ones(y.shape[0])\n",
    "    nonzero = y.nonzero()\n",
    "    vec[nonzero[:,0]] = nonzero[:,1].float()\n",
    "    \n",
    "    return create_splits(vec)\n",
    "\n",
    "def alpaydin_F_test(c1_acc_lst, c2_acc_lst):\n",
    "    # acc_list := [np.array([acc_ij, acc_i(j+1)]) for i in 5, j in 2]\n",
    "    assert len(c1_acc_lst) == len(c2_acc_lst)\n",
    "    diff_acc_lst = [c1_acc_lst[i] - c2_acc_lst[i] for i in range(len(c1_acc_lst))]\n",
    "    \n",
    "    mean_lst = [np.mean(a) for a in diff_acc_lst] \n",
    "    var_lst = [ (diff_acc_lst[i][0] - mean_lst[i])**2\n",
    "               +(diff_acc_lst[i][1] - mean_lst[i])**2 for i in range(len(diff_acc_lst))]\n",
    "    \n",
    "    numerator = sum([sum(a**2) for a in diff_acc_lst])\n",
    "    denumerator = 2 * sum(var_lst)\n",
    "    f = numerator / denumerator\n",
    "    p_value = stats.f.sf(f, 10, 5)\n",
    "    \n",
    "    return (f, p_value, np.mean(mean_lst), np.mean(var_lst))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure same datasets per model\n",
    "likert_crowd_splits = [create_splits(y_likert_crowd[likert_crowd_idx]) for i in range(5)]\n",
    "likert_expert_splits = [create_splits(y_likert_experts[likert_expert_idx]) for i in range(5)]\n",
    "likert_combined_splits = [create_splits(y_likert_combined[likert_combined_idx]) for i in range(5)]\n",
    "\n",
    "dominant_crowd_splits = [create_splits(y_dominant_crowd[dominant_crowd_idx]) for i in range(5)]\n",
    "dominant_expert_splits = [create_splits(y_dominant_experts[dominant_expert_idx]) for i in range(5)]\n",
    "dominant_combined_splits = [create_splits(y_dominant_combined[dominant_combined_idx]) for i in range(5)]\n",
    "\n",
    "labels = ['expert_likert', 'crowd_likert', 'combined_likert',\n",
    "          'expert_dominant', 'crowd_dominant', 'combined_dominant']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_class(y):\n",
    "    ct = Counter(y)\n",
    "    return ct.most_common(1)[0][1] / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class accuracy on Likert labels (baseline)\n",
      " crowd labels:  0.2437\n",
      " expert labels: 0.2241\n",
      " combined labels: 0.2521\n",
      "\n",
      "Majority class accuracy on Dominant labels (baseline)\n",
      " crowd labels:  0.5400\n",
      " expert labels: 0.6383\n",
      " combined labels: 0.5766\n"
     ]
    }
   ],
   "source": [
    "majority_class_acc_crowd_likert = majority_class(y_likert_crowd[likert_crowd_idx])\n",
    "majority_class_acc_experts_likert = majority_class(y_likert_experts[likert_expert_idx])\n",
    "majority_class_acc_combined_likert = majority_class(y_likert_combined[likert_combined_idx])\n",
    "\n",
    "print(\"Majority class accuracy on Likert labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_likert))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_likert))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_likert))\n",
    "\n",
    "majority_class_acc_crowd_dominant = majority_class(y_dominant_crowd[dominant_crowd_idx])\n",
    "majority_class_acc_experts_dominant = majority_class(y_dominant_experts[dominant_expert_idx])\n",
    "majority_class_acc_combined_dominant = majority_class(y_dominant_combined[dominant_combined_idx])\n",
    "\n",
    "print(\"\\nMajority class accuracy on Dominant labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_dominant))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_dominant))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_dominant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (supervised)\n",
    "\n",
    "We start with a traditional, or 'shallow', machine learning model: random forest. Because random forest does not support iterative learning, we test both the crowd and expert sets separately.\n",
    "\n",
    "We use stratified cross validation to reduce the effects caused by the small size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = [100, 250, 500, 750, 1000, 2000]\n",
    "\n",
    "def random_forest(X, y, index, splits, n_estimators=N_ESTIMATORS):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_est_lst = list()\n",
    "    for n_estimators in N_ESTIMATORS:\n",
    "        print(\"Training with {} estimators\".format(n_estimators))\n",
    "        acc_lst = list()\n",
    "        for fold_i in range(5):\n",
    "            print(\" Starting outer fold {} / {}\".format(fold_i+1, 5))\n",
    "            acc_inner = list()\n",
    "            split_a_idx, split_b_idx  = splits[fold_i]\n",
    "            for fold_j in range(2):\n",
    "                print(\"  Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "                if fold_j % 2 == 0:\n",
    "                    train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "                else:\n",
    "                    train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "\n",
    "                train_idx = index[train_fold_idx]\n",
    "                test_idx = index[test_fold_idx]\n",
    "\n",
    "                model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "                y_pred = model.predict(X[test_idx])\n",
    "                fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "\n",
    "                acc_inner.append(fold_acc)\n",
    "                print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "\n",
    "            acc_lst.append(np.array(acc_inner))\n",
    "        print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "        acc_est_lst.append(acc_lst)\n",
    "    \n",
    "    return acc_est_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1538)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.0938)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1788\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0769)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1837\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2053\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2500)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " => mean acc: 0.2154\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2022\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2188)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1562)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2308)\n",
      " => mean acc: 0.2123\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.607150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.440255</td>\n",
       "      <td>0.676905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.182670</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.639681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.576338</td>\n",
       "      <td>0.704997</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.622674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.571985</td>\n",
       "      <td>0.630378</td>\n",
       "      <td>0.671688</td>\n",
       "      <td>0.647048</td>\n",
       "      <td>0.266784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.607150       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.440255  0.676905       NaN       NaN       NaN   NaN\n",
       "3       750  0.182670  0.534881  0.639681       NaN       NaN   NaN\n",
       "4      1000  0.576338  0.704997  0.534881  0.622674       NaN   NaN\n",
       "5      2000  0.571985  0.630378  0.671688  0.647048  0.266784   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "random_forest_acc_experts_likert = random_forest(X_2D,\n",
    "                                                 y_likert_experts, \n",
    "                                                 likert_expert_idx,\n",
    "                                                 likert_expert_splits)\n",
    "\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_experts_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_experts_likert[i],\n",
    "                                               random_forest_acc_experts_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.3333)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " => mean acc: 0.2065\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " => mean acc: 0.1979\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2258)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2258)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " => mean acc: 0.2193\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2258)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " => mean acc: 0.2142\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " => mean acc: 0.2079\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1935)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2456)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2632)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2281)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.2105)\n",
      " => mean acc: 0.2061\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.679823</td>\n",
       "      <td>0.170021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.401540</td>\n",
       "      <td>0.303533</td>\n",
       "      <td>0.094303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.620144</td>\n",
       "      <td>0.195904</td>\n",
       "      <td>0.329561</td>\n",
       "      <td>0.278073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.711632</td>\n",
       "      <td>0.666157</td>\n",
       "      <td>0.418412</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.71428</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750     1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN      NaN   NaN\n",
       "1       250  0.591246       NaN       NaN       NaN      NaN   NaN\n",
       "2       500  0.679823  0.170021       NaN       NaN      NaN   NaN\n",
       "3       750  0.401540  0.303533  0.094303       NaN      NaN   NaN\n",
       "4      1000  0.620144  0.195904  0.329561  0.278073      NaN   NaN\n",
       "5      2000  0.711632  0.666157  0.418412  0.050903  0.71428   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "random_forest_acc_crowd_likert = random_forest(X_2D,\n",
    "                                               y_likert_crowd,\n",
    "                                               likert_crowd_idx,\n",
    "                                               likert_crowd_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_crowd_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_crowd_likert[i],\n",
    "                                               random_forest_acc_crowd_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1448\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1392\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1228)\n",
      " => mean acc: 0.1368\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0702)\n",
      " => mean acc: 0.1249\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0702)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " => mean acc: 0.1181\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0702)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0702)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " => mean acc: 0.1216\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.796171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.788404</td>\n",
       "      <td>0.776071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.724592</td>\n",
       "      <td>0.638277</td>\n",
       "      <td>0.450443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.675741</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.245731</td>\n",
       "      <td>0.637919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>0.599058</td>\n",
       "      <td>0.388019</td>\n",
       "      <td>0.376932</td>\n",
       "      <td>0.241633</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.796171       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.788404  0.776071       NaN       NaN       NaN   NaN\n",
       "3       750  0.724592  0.638277  0.450443       NaN       NaN   NaN\n",
       "4      1000  0.675741  0.534881  0.245731  0.637919       NaN   NaN\n",
       "5      2000  0.650089  0.599058  0.388019  0.376932  0.241633   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "random_forest_acc_combined_likert = random_forest(X_2D,\n",
    "                                                  y_likert_combined,\n",
    "                                                  likert_combined_idx,\n",
    "                                                  likert_combined_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_combined_likert)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_combined_likert[i],\n",
    "                                               random_forest_acc_combined_likert[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " => mean acc: 0.6181\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6303\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.6250)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6219\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6178\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6136\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6957)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5417)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.6522)\n",
      " => mean acc: 0.6096\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.653275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.635211</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.675690</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.674036</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.653275       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.635211  0.534881       NaN       NaN       NaN   NaN\n",
       "3       750  0.675690  0.534881  0.534881       NaN       NaN   NaN\n",
       "4      1000  0.534881  0.534881  0.534881  0.534881       NaN   NaN\n",
       "5      2000  0.674036  0.534881  0.534881  0.534881  0.534881   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "random_forest_acc_experts_dominant = random_forest(X_2D,\n",
    "                                                   y_dominant_experts, \n",
    "                                                   dominant_expert_idx,\n",
    "                                                   dominant_expert_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_experts_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_experts_dominant[i],\n",
    "                                               random_forest_acc_experts_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5200)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " => mean acc: 0.4540\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " => mean acc: 0.4440\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " => mean acc: 0.4440\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " => mean acc: 0.4300\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " => mean acc: 0.4260\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4200)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4400)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4400)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.3600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5200)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4600)\n",
      " => mean acc: 0.4260\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.498882</td>\n",
       "      <td>0.282640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.610752</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>0.470463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.630830</td>\n",
       "      <td>0.621064</td>\n",
       "      <td>0.311028</td>\n",
       "      <td>0.684453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.395471</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>0.193042</td>\n",
       "      <td>0.504873</td>\n",
       "      <td>0.593013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.778215       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.498882  0.282640       NaN       NaN       NaN   NaN\n",
       "3       750  0.610752  0.724354  0.470463       NaN       NaN   NaN\n",
       "4      1000  0.630830  0.621064  0.311028  0.684453       NaN   NaN\n",
       "5      2000  0.395471  0.616169  0.193042  0.504873  0.593013   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "random_forest_acc_crowd_dominant = random_forest(X_2D,\n",
    "                                                 y_dominant_crowd,\n",
    "                                                 dominant_crowd_idx,\n",
    "                                                 dominant_crowd_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_crowd_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_crowd_dominant[i],\n",
    "                                               random_forest_acc_crowd_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4286)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " => mean acc: 0.4793\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5455)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5091)\n",
      " => mean acc: 0.4974\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5273)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4182)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " => mean acc: 0.4719\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " => mean acc: 0.4827\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4909)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " => mean acc: 0.4792\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting outer fold 1 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 2 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4821)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 3 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4727)\n",
      " Starting outer fold 4 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 5 / 5\n",
      "  Starting inner fold 1 / 2 (acc: 0.4464)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " => mean acc: 0.4684\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>0.417440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.378858</td>\n",
       "      <td>0.492505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750</td>\n",
       "      <td>0.761105</td>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.653874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.674261</td>\n",
       "      <td>0.363360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.593127</td>\n",
       "      <td>0.262362</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>0.617982</td>\n",
       "      <td>0.156792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p-values       100       250       500       750      1000  2000\n",
       "0       100       NaN       NaN       NaN       NaN       NaN   NaN\n",
       "1       250  0.417440       NaN       NaN       NaN       NaN   NaN\n",
       "2       500  0.378858  0.492505       NaN       NaN       NaN   NaN\n",
       "3       750  0.761105  0.629956  0.653874       NaN       NaN   NaN\n",
       "4      1000  0.534881  0.534881  0.674261  0.363360       NaN   NaN\n",
       "5      2000  0.593127  0.262362  0.534881  0.617982  0.156792   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "random_forest_acc_combined_dominant = random_forest(X_2D,\n",
    "                                                    y_dominant_combined,\n",
    "                                                    dominant_combined_idx,\n",
    "                                                    dominant_combined_splits)\n",
    "table = {'p-values': N_ESTIMATORS}\n",
    "table.update({est: list() for est in N_ESTIMATORS})\n",
    "nhypotheses = len(random_forest_acc_combined_dominant)\n",
    "for i in range(nhypotheses):\n",
    "    for e in range(i+1):\n",
    "        table[N_ESTIMATORS[i]].append(np.nan)\n",
    "    for j in range(i+1, nhypotheses):\n",
    "        f, p, mean, variance = alpaydin_F_test(random_forest_acc_combined_dominant[i],\n",
    "                                               random_forest_acc_combined_dominant[j])\n",
    "        table[N_ESTIMATORS[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(N_ESTIMATORS[i], N_ESTIMATORS[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "def pac(X, y, index, splits):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_lst = list()\n",
    "    for fold_i in range(5):\n",
    "        print(\" Starting outer fold {} / {}\".format(fold_i+1, 5), end='')\n",
    "        acc_inner = list()\n",
    "        split_a_idx, split_b_idx  = splits[fold_i]\n",
    "        for fold_j in range(2):\n",
    "            print(\"  Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "            if fold_j % 2 == 0:\n",
    "                train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "            else:\n",
    "                train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "\n",
    "            train_idx = index[train_fold_idx]\n",
    "            test_idx = index[test_fold_idx]\n",
    "\n",
    "            model = PassiveAggressiveClassifier(max_iter=2000, warm_start=False)\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    " \n",
    "            y_pred = model.predict(X[test_idx])\n",
    "            fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "\n",
    "            acc_inner.append(fold_acc)\n",
    "            print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "            \n",
    "        acc_lst.append(np.array(acc_inner))\n",
    "    print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "    \n",
    "    return acc_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.1875)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1923)\n",
      " => mean acc: 0.1899\n",
      "\n",
      "=== Results of supervised learning on crowd likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.1774)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1053)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.2097)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " => mean acc: 0.1618\n",
      "\n",
      "=== Results of supervised learning on combined likert labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.1290)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.0877)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.1129)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1754)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.1452)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1404)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.1613)\n",
      "  Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1448\n",
      "\n",
      "=== Results of supervised learning on expert dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4348)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.6667)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.5833)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4783)\n",
      " => mean acc: 0.5598\n",
      "\n",
      "=== Results of supervised learning on crowd dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.3200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.4800)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.4600)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.5200)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5000)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " => mean acc: 0.4700\n",
      "\n",
      "=== Results of supervised learning on combined dominant labels ===\n",
      " Starting outer fold 1 / 5  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " Starting outer fold 2 / 5  Starting inner fold 1 / 2 (acc: 0.4286)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " Starting outer fold 3 / 5  Starting inner fold 1 / 2 (acc: 0.5000)\n",
      "  Starting inner fold 2 / 2 (acc: 0.5273)\n",
      " Starting outer fold 4 / 5  Starting inner fold 1 / 2 (acc: 0.4643)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4545)\n",
      " Starting outer fold 5 / 5  Starting inner fold 1 / 2 (acc: 0.5179)\n",
      "  Starting inner fold 2 / 2 (acc: 0.4364)\n",
      " => mean acc: 0.4702\n",
      "\n",
      "= p-values =\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>0.551877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>0.150591</td>\n",
       "      <td>0.642129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.613049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.476899</td>\n",
       "      <td>0.572275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values  expert_likert  crowd_likert  combined_likert  \\\n",
       "0      expert_likert            NaN           NaN              NaN   \n",
       "1       crowd_likert       0.551877           NaN              NaN   \n",
       "2    combined_likert       0.150591      0.642129              NaN   \n",
       "3    expert_dominant       0.016100      0.001855         0.013874   \n",
       "4     crowd_dominant       0.000673      0.004439         0.000087   \n",
       "5  combined_dominant       0.000131      0.000401         0.000418   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3              NaN             NaN                NaN  \n",
       "4         0.613049             NaN                NaN  \n",
       "5         0.476899        0.572275                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "pac_acc_experts_likert = pac(X_2D,\n",
    "                                y_likert_experts, \n",
    "                                likert_expert_idx,\n",
    "                                likert_expert_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "pac_acc_crowd_likert = pac(X_2D,\n",
    "                              y_likert_crowd,\n",
    "                              likert_crowd_idx,\n",
    "                              likert_crowd_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "pac_acc_combined_likert = pac(X_2D,\n",
    "                                 y_likert_combined,\n",
    "                                 likert_combined_idx,\n",
    "                                 likert_combined_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "pac_acc_experts_dominant = pac(X_2D,\n",
    "                                  y_dominant_experts, \n",
    "                                  dominant_expert_idx,\n",
    "                                  dominant_expert_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "pac_acc_crowd_dominant = pac(X_2D,\n",
    "                                y_dominant_crowd,\n",
    "                                dominant_crowd_idx,\n",
    "                                dominant_crowd_splits)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "pac_acc_combined_dominant = pac(X_2D,\n",
    "                                   y_dominant_combined,\n",
    "                                   dominant_combined_idx,\n",
    "                                   dominant_combined_splits)\n",
    "\n",
    "pac_acc = [pac_acc_experts_likert, pac_acc_crowd_likert, pac_acc_combined_likert,\n",
    "           pac_acc_experts_dominant, pac_acc_crowd_dominant, pac_acc_combined_dominant]\n",
    "\n",
    "print(\"= p-values =\")\n",
    "table = {'p-values': labels}\n",
    "table.update({lab: list() for lab in labels})\n",
    "nlabels = len(labels)\n",
    "for i in range(nlabels):\n",
    "    for e in range(i+1):\n",
    "        table[labels[i]].append(np.nan)\n",
    "    for j in range(i+1, nlabels):\n",
    "        f, p, mean, variance = alpaydin_F_test(pac_acc[i],\n",
    "                                               pac_acc[j])\n",
    "        table[labels[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(pac_acc[i], pac_acc[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incremental learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert numpy arrays to PyTorch tensors\n",
    "X_2D = torch.from_numpy(X_2D)\n",
    "X_3D = torch.from_numpy(X_3D)\n",
    "y_likert_crowd = torch.from_numpy(y_likert_crowd)\n",
    "y_likert_experts = torch.from_numpy(y_likert_experts)\n",
    "y_likert_combined = torch.from_numpy(y_likert_combined)\n",
    "y_dominant_crowd = torch.from_numpy(y_dominant_crowd)\n",
    "y_dominant_experts = torch.from_numpy(y_dominant_experts)\n",
    "y_dominant_combined = torch.from_numpy(y_dominant_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(y_hat, y):\n",
    "    # y := 1D array of class labels\n",
    "    # y_hat := 2D array of one-hot class labels\n",
    "    _, labels = y_hat.max(dim=1)\n",
    "    return torch.mean(torch.eq(labels, y).float())\n",
    "\n",
    "def fit(model, X, y, index, splits, lr=0.01, l2norm=0.01, n_epoch=250, patience=-1):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc_lst = list()\n",
    "    for fold_i in range(5):\n",
    "        print(\"Starting outer fold {} / {}\".format(fold_i+1, 5))\n",
    "        acc_inner = list()\n",
    "        split_a_idx, split_b_idx  = splits[fold_i]\n",
    "\n",
    "        for fold_j in range(2):\n",
    "            print(\" Starting inner fold {} / {}\".format(fold_j+1, 2), end='')\n",
    "            if fold_j % 2 == 0:\n",
    "                train_fold_idx, test_fold_idx  = split_a_idx, split_b_idx\n",
    "            else:\n",
    "                train_fold_idx, test_fold_idx  = split_b_idx, split_a_idx\n",
    "                \n",
    "            train_idx = index[train_fold_idx]\n",
    "            test_idx = index[test_fold_idx]\n",
    "            \n",
    "            model.init()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            # early stopping\n",
    "            patience_left = patience\n",
    "            best_fold_score = -1\n",
    "            delta = 1e-4\n",
    "            best_fold_state = None\n",
    "            best_fold_state_opt = None\n",
    "        \n",
    "            for epoch in range(n_epoch):\n",
    "                model.train()\n",
    "\n",
    "                y_hat = model(X[train_idx].float())\n",
    "                train_acc = categorical_accuracy(y_hat, y[train_idx])\n",
    "                train_loss = criterion(y_hat, y[train_idx].long())\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                test_loss = None\n",
    "                with torch.no_grad():\n",
    "                    y_hat = model(X[test_idx].float())\n",
    "                    test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "                    test_loss = criterion(y_hat, y[test_idx].long())\n",
    "\n",
    "                train_loss = float(train_loss.item())\n",
    "                test_loss = float(test_loss.item())\n",
    "                \n",
    "                if best_fold_score < 0:\n",
    "                    best_fold_score = test_loss\n",
    "                    best_fold_state = model.state_dict()\n",
    "                    best_fold_state_opt = optimizer.state_dict()\n",
    "\n",
    "                if patience <= 0:\n",
    "                    continue\n",
    "                if test_loss >= best_fold_score - delta:\n",
    "                    patience_left -= 1\n",
    "                else:\n",
    "                    best_fold_score = test_loss\n",
    "                    best_fold_state = model.state_dict()\n",
    "                    best_fold_state_opt = optimizer.state_dict()\n",
    "                    patience_left = patience\n",
    "                if patience_left <= 0:\n",
    "                    model.load_state_dict(best_fold_state)\n",
    "                    optimizer.load_state_dict(best_fold_state_opt)\n",
    "                    break\n",
    "            \n",
    "            # do a final run over the test set after loading a previous state\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(X[test_idx].float())\n",
    "                test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "                test_loss = criterion(y_hat, y[test_idx].long())\n",
    "            \n",
    "            test_loss = float(test_loss.item())\n",
    "            print(\" (acc: {:.4f})\".format(test_acc))\n",
    "            acc_inner.append(test_acc)\n",
    "    \n",
    "        acc_lst.append(np.array(acc_inner))\n",
    "        \n",
    "    print(\" => mean acc: {:.4f}\\n\".format(np.mean(np.array([np.mean(inner) for inner in acc_lst]))))\n",
    "\n",
    "    return acc_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNN(nn.Module):\n",
    "    \"\"\"Simple Neural Network Classifier\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, p_dropout=0.05):\n",
    "        super().__init__()\n",
    "        hidden_dim = (input_dim-output_dim)//2\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(input_dim, hidden_dim),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(p=p_dropout)))\n",
    "            \n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(hidden_dim, output_dim),\n",
    "                            nn.ReLU(inplace=True)))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)                          \n",
    "                           \n",
    "        return self.softmax(X)\n",
    "        \n",
    "    def init(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1250)\n",
      " Starting inner fold 2 / 2 (acc: 0.1923)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1250)\n",
      " Starting inner fold 2 / 2 (acc: 0.2308)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1875)\n",
      " Starting inner fold 2 / 2 (acc: 0.2692)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1562)\n",
      " Starting inner fold 2 / 2 (acc: 0.0385)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.0938)\n",
      " Starting inner fold 2 / 2 (acc: 0.2692)\n",
      " => mean acc: 0.1688\n",
      "\n",
      "\n",
      "=== Results on crowd likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.2097)\n",
      " Starting inner fold 2 / 2 (acc: 0.1404)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1452)\n",
      " Starting inner fold 2 / 2 (acc: 0.2281)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1774)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1290)\n",
      " Starting inner fold 2 / 2 (acc: 0.1579)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1774)\n",
      " Starting inner fold 2 / 2 (acc: 0.1930)\n",
      " => mean acc: 0.1663\n",
      "\n",
      "\n",
      "=== Results on combined likert labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1774)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.2097)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.0806)\n",
      " Starting inner fold 2 / 2 (acc: 0.1754)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.1129)\n",
      " Starting inner fold 2 / 2 (acc: 0.1053)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.2097)\n",
      " Starting inner fold 2 / 2 (acc: 0.1579)\n",
      " => mean acc: 0.1439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_2D.shape[1]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert likert labels ===\")\n",
    "neural_net_acc_likert_experts = fit(model, X_2D, y_likert_experts, likert_expert_idx, likert_expert_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd likert labels ===\")\n",
    "neural_net_acc_likert_crowd = fit(model, X_2D, y_likert_crowd, likert_crowd_idx, likert_crowd_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined likert labels ===\")\n",
    "neural_net_acc_likert_combined = fit(model, X_2D, y_likert_combined, likert_combined_idx, likert_combined_splits, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.7083)\n",
      " Starting inner fold 2 / 2 (acc: 0.5217)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.6250)\n",
      " Starting inner fold 2 / 2 (acc: 0.6087)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5417)\n",
      " Starting inner fold 2 / 2 (acc: 0.6087)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.6667)\n",
      " Starting inner fold 2 / 2 (acc: 0.6087)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.6250)\n",
      " Starting inner fold 2 / 2 (acc: 0.3913)\n",
      " => mean acc: 0.5906\n",
      "\n",
      "\n",
      "=== Results on crowd dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4400)\n",
      " Starting inner fold 2 / 2 (acc: 0.4800)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4400)\n",
      " Starting inner fold 2 / 2 (acc: 0.4600)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4400)\n",
      " Starting inner fold 2 / 2 (acc: 0.4200)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4400)\n",
      " Starting inner fold 2 / 2 (acc: 0.4800)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4200)\n",
      " Starting inner fold 2 / 2 (acc: 0.4800)\n",
      " => mean acc: 0.4500\n",
      "\n",
      "\n",
      "=== Results on combined dominant labels ===\n",
      "Starting outer fold 1 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5000)\n",
      " Starting inner fold 2 / 2 (acc: 0.5273)\n",
      "Starting outer fold 2 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4107)\n",
      " Starting inner fold 2 / 2 (acc: 0.4364)\n",
      "Starting outer fold 3 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.5714)\n",
      " Starting inner fold 2 / 2 (acc: 0.4545)\n",
      "Starting outer fold 4 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4464)\n",
      " Starting inner fold 2 / 2 (acc: 0.5091)\n",
      "Starting outer fold 5 / 5\n",
      " Starting inner fold 1 / 2 (acc: 0.4643)\n",
      " Starting inner fold 2 / 2 (acc: 0.6182)\n",
      " => mean acc: 0.4938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.1\n",
    "\n",
    "## define model\n",
    "indim = X_2D.shape[1]\n",
    "outdim = np.unique(y_dominant_experts[dominant_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_dominant_crowd[dominant_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "neural_net_acc_dominant_experts = fit(model, X_2D, y_dominant_experts, dominant_expert_idx, dominant_expert_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "neural_net_acc_dominant_crowd = fit(model, X_2D, y_dominant_crowd, dominant_crowd_idx, dominant_crowd_splits, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined dominant labels ===\")\n",
    "neural_net_acc_dominant_combined = fit(model, X_2D, y_dominant_combined, dominant_combined_idx, dominant_combined_splits, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= p-values =\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>0.690525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>0.723761</td>\n",
       "      <td>0.772045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>0.017340</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.251405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.472237</td>\n",
       "      <td>0.159677</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p-values  expert_likert  crowd_likert  combined_likert  \\\n",
       "0      expert_likert            NaN           NaN              NaN   \n",
       "1       crowd_likert       0.690525           NaN              NaN   \n",
       "2    combined_likert       0.723761      0.772045              NaN   \n",
       "3    expert_dominant       0.017340      0.003085         0.000491   \n",
       "4     crowd_dominant       0.004036      0.000395         0.002835   \n",
       "5  combined_dominant       0.004726      0.000665         0.008233   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3              NaN             NaN                NaN  \n",
       "4         0.251405             NaN                NaN  \n",
       "5         0.472237        0.159677                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_acc = [neural_net_acc_likert_experts, neural_net_acc_likert_crowd, neural_net_acc_likert_combined,\n",
    "          neural_net_acc_dominant_experts, neural_net_acc_dominant_crowd, neural_net_acc_dominant_combined]\n",
    "\n",
    "print(\"= p-values =\")\n",
    "table = {'p-values': labels}\n",
    "table.update({lab: list() for lab in labels})\n",
    "nlabels = len(labels)\n",
    "for i in range(nlabels):\n",
    "    for e in range(i+1):\n",
    "        table[labels[i]].append(np.nan)\n",
    "    for j in range(i+1, nlabels):\n",
    "        f, p, mean, variance = alpaydin_F_test(nn_acc[i],\n",
    "                                               nn_acc[j])\n",
    "        table[labels[i]].append(p)\n",
    "        #print(\"RF {} vs {} estimators\".format(nn_acc[i], nn_acc[j]))\n",
    "        #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "significance = pd.DataFrame(table)\n",
    "display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 100 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.575061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 100 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.002806           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000481              NaN   \n",
       "2           combined_likert            NaN           NaN         0.000134   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.195578             NaN                NaN  \n",
       "4              NaN        0.575061                NaN  \n",
       "5              NaN             NaN            0.60138  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 250 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.350589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 250 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.001756           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000051              NaN   \n",
       "2           combined_likert            NaN           NaN         0.000679   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.350589             NaN                NaN  \n",
       "4              NaN        0.050575                NaN  \n",
       "5              NaN             NaN           0.440032  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 500 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.133173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 500 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.004805           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.001807              NaN   \n",
       "2           combined_likert            NaN           NaN         0.000163   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.133173             NaN                NaN  \n",
       "4              NaN        0.634535                NaN  \n",
       "5              NaN             NaN           0.660148  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 750 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.011546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539067</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 750 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0             expert_likert       0.011546           NaN              NaN   \n",
       "1              crowd_likert            NaN      0.000481              NaN   \n",
       "2           combined_likert            NaN           NaN         0.000163   \n",
       "3           expert_dominant            NaN           NaN              NaN   \n",
       "4            crowd_dominant            NaN           NaN              NaN   \n",
       "5         combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.160609             NaN                NaN  \n",
       "4              NaN        0.539067                NaN  \n",
       "5              NaN             NaN           0.666082  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 1000 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 1000 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0              expert_likert       0.005963           NaN              NaN   \n",
       "1               crowd_likert            NaN      0.000531              NaN   \n",
       "2            combined_likert            NaN           NaN         0.000217   \n",
       "3            expert_dominant            NaN           NaN              NaN   \n",
       "4             crowd_dominant            NaN           NaN              NaN   \n",
       "5          combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3         0.221846             NaN                NaN  \n",
       "4              NaN        0.306752                NaN  \n",
       "5              NaN             NaN           0.541504  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p-values - 2000 estimators</th>\n",
       "      <th>expert_likert</th>\n",
       "      <th>crowd_likert</th>\n",
       "      <th>combined_likert</th>\n",
       "      <th>expert_dominant</th>\n",
       "      <th>crowd_dominant</th>\n",
       "      <th>combined_dominant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expert_likert</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crowd_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined_likert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>expert_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crowd_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combined_dominant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p-values - 2000 estimators  expert_likert  crowd_likert  combined_likert  \\\n",
       "0              expert_likert       0.003826           NaN              NaN   \n",
       "1               crowd_likert            NaN      0.000591              NaN   \n",
       "2            combined_likert            NaN           NaN         0.000243   \n",
       "3            expert_dominant            NaN           NaN              NaN   \n",
       "4             crowd_dominant            NaN           NaN              NaN   \n",
       "5          combined_dominant            NaN           NaN              NaN   \n",
       "\n",
       "   expert_dominant  crowd_dominant  combined_dominant  \n",
       "0              NaN             NaN                NaN  \n",
       "1              NaN             NaN                NaN  \n",
       "2              NaN             NaN                NaN  \n",
       "3          0.19321             NaN                NaN  \n",
       "4              NaN        0.636653                NaN  \n",
       "5              NaN             NaN           0.528828  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_acc = [random_forest_acc_experts_likert, random_forest_acc_crowd_likert, random_forest_acc_combined_likert,\n",
    "           random_forest_acc_experts_dominant, random_forest_acc_crowd_dominant, random_forest_acc_combined_dominant]\n",
    "\n",
    "nhypotheses = len(N_ESTIMATORS)\n",
    "for k in range(nhypotheses):\n",
    "    table = {'p-values - {} estimators'.format(N_ESTIMATORS[k]): labels}\n",
    "    table.update({lab: list() for lab in labels})\n",
    "\n",
    "    nlabels = len(labels)\n",
    "    for i in range(nlabels):\n",
    "        for e in range(nlabels):\n",
    "            if e != i:\n",
    "                table[labels[i]].append(np.nan)\n",
    "            else:\n",
    "                f, p, mean, variance = alpaydin_F_test(nn_acc[i],\n",
    "                                                       rf_acc[j][k])\n",
    "                table[labels[i]].append(p)\n",
    "                #print(\"RF {} vs {} estimators\".format(nn_acc[i], nn_acc[j]))\n",
    "                #print(\" f: {:.4f}, p: {:.4f}, mean: {:.4f}, var: {:.4f}\".format(f, p, mean, variance))\n",
    "\n",
    "    significance = pd.DataFrame(table)\n",
    "    display(significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
