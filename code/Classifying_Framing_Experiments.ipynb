{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn\n",
    "#%pip install torch\n",
    "\n",
    "from math import sqrt\n",
    "import os\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "## project structure\n",
    "DATA_DIR = \"/data/projects/capturingBias/research/framing/data/\"  # change to \"./\" for current directory\n",
    "DATA_NPZ = DATA_DIR + \"data.npz\"\n",
    "\n",
    "## load files\n",
    "data = np.load(DATA_NPZ)\n",
    "\n",
    "X_2D = data['X_2D']\n",
    "X_3D = data['X_3D']\n",
    "y_likert_crowd = data['y_likert_crowd']\n",
    "y_likert_experts = data['y_likert_experts']\n",
    "y_dominant_crowd = data['y_dominant_crowd']\n",
    "y_dominant_experts = data['y_dominant_experts']\n",
    "y_likert_combined = data['y_likert_combined']\n",
    "y_dominant_combined = data['y_dominant_combined']\n",
    "\n",
    "\n",
    "# likert\n",
    "likert_expert_idx = np.where(y_likert_experts > -1)[0]\n",
    "likert_crowd_idx = np.setdiff1d(np.where(y_likert_crowd > -1)[0],\n",
    "                                likert_expert_idx,\n",
    "                                assume_unique=True)\n",
    "likert_combined_idx = np.concatenate([likert_crowd_idx,\n",
    "                                      likert_expert_idx])\n",
    "\n",
    "# dominant\n",
    "dominant_expert_idx = np.where(y_dominant_experts > -1)[0]\n",
    "dominant_crowd_idx = np.setdiff1d(np.where(y_dominant_crowd > -1)[0],\n",
    "                                  dominant_expert_idx,\n",
    "                                  assume_unique=True)\n",
    "dominant_combined_idx = np.concatenate([dominant_crowd_idx,\n",
    "                                        dominant_expert_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=-1):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(0, 2**32-1)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "#set_seed(47)  # make reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(y, test_ratio=.2):\n",
    "    train_idx = list()\n",
    "    test_idx = list()\n",
    "    \n",
    "    strats = [np.where(y == lab)[0] for lab in np.unique(y) if lab > -1]\n",
    "    for strat in strats:\n",
    "        n = strat.shape[0]\n",
    "        train_idx.append(strat[:int(n*(1-test_ratio))])\n",
    "        test_idx.append(strat[int(n*(1-test_ratio)):])\n",
    "        \n",
    "    train_idx = np.concatenate(train_idx)\n",
    "    test_idx = np.concatenate(test_idx)\n",
    "    \n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(test_idx)\n",
    "    \n",
    "    return (train_idx, test_idx)\n",
    "\n",
    "def create_splits_one_hot(y):\n",
    "    vec = -np.ones(y.shape[0])\n",
    "    nonzero = y.nonzero()\n",
    "    vec[nonzero[:,0]] = nonzero[:,1].float()\n",
    "    \n",
    "    return create_splits(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def majority_class(y):\n",
    "    ct = Counter(y)\n",
    "    return ct.most_common(1)[0][1] / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class accuracy on Likert labels (baseline)\n",
      " crowd labels:  0.2787\n",
      " expert labels: 0.2414\n",
      " combined labels: 0.2521\n",
      "\n",
      "Majority class accuracy on Dominant labels (baseline)\n",
      " crowd labels:  0.6250\n",
      " expert labels: 0.5345\n",
      " combined labels: 0.5789\n"
     ]
    }
   ],
   "source": [
    "majority_class_acc_crowd_likert = majority_class(y_likert_crowd[likert_crowd_idx])\n",
    "majority_class_acc_experts_likert = majority_class(y_likert_experts[likert_expert_idx])\n",
    "majority_class_acc_combined_likert = majority_class(y_likert_combined[likert_combined_idx])\n",
    "\n",
    "print(\"Majority class accuracy on Likert labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_likert))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_likert))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_likert))\n",
    "\n",
    "majority_class_acc_crowd_dominant = majority_class(y_dominant_crowd[dominant_crowd_idx])\n",
    "majority_class_acc_experts_dominant = majority_class(y_dominant_experts[dominant_expert_idx])\n",
    "majority_class_acc_combined_dominant = majority_class(y_dominant_combined[dominant_combined_idx])\n",
    "\n",
    "print(\"\\nMajority class accuracy on Dominant labels (baseline)\")\n",
    "print(\" crowd labels:  {:.4f}\".format(majority_class_acc_crowd_dominant))\n",
    "print(\" expert labels: {:.4f}\".format(majority_class_acc_experts_dominant))\n",
    "print(\" combined labels: {:.4f}\".format(majority_class_acc_combined_dominant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (supervised)\n",
    "\n",
    "We start with a traditional, or 'shallow', machine learning model: random forest. Because random forest does not support iterative learning, we test both the crowd and expert sets separately.\n",
    "\n",
    "We use stratified cross validation to reduce the effects caused by the small size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "N_ESTIMATORS = [100, 250, 500, 750, 1000, 2000]\n",
    "N_FOLDS = 10\n",
    "\n",
    "def random_forest(X, y, index, n_folds=N_FOLDS, n_estimators=N_ESTIMATORS):\n",
    "    n_samples = X[index].shape[0]\n",
    "    for n_estimators in N_ESTIMATORS:\n",
    "        print(\"Training with {} estimators\".format(n_estimators))\n",
    "        acc = 0\n",
    "        for fold_i in range(N_FOLDS):\n",
    "            print(\" Starting fold {} / {}\".format(fold_i+1, N_FOLDS), end='')\n",
    "            \n",
    "            train_fold_idx, test_fold_idx  = create_splits(y[index])\n",
    "            train_idx = index[train_fold_idx]\n",
    "            test_idx = index[test_fold_idx]\n",
    "        \n",
    "            model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            \n",
    "            y_pred = model.predict(X[test_idx])\n",
    "            fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "        \n",
    "            acc += fold_acc\n",
    "            print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "            \n",
    "        acc /= N_FOLDS\n",
    "        print(\"Mean accuracy on test set: {:.4f}\\n\".format(acc))\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.1333)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.1333)\n",
      " Starting fold 7 / 10 (acc: 0.0667)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.1333)\n",
      " Starting fold 10 / 10 (acc: 0.1333)\n",
      "Mean accuracy on test set: 0.1533\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1800\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.1333)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.1333)\n",
      " Starting fold 7 / 10 (acc: 0.1333)\n",
      " Starting fold 8 / 10 (acc: 0.1333)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1600\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.1333)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.1333)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.1333)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.1333)\n",
      "Mean accuracy on test set: 0.1667\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.1333)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.1333)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1667\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "random_forest_acc_experts_likert = random_forest(X_2D,\n",
    "                                                 y_likert_experts, \n",
    "                                                 likert_expert_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2667)\n",
      " Starting fold 4 / 10 (acc: 0.0667)\n",
      " Starting fold 5 / 10 (acc: 0.2667)\n",
      " Starting fold 6 / 10 (acc: 0.2667)\n",
      " Starting fold 7 / 10 (acc: 0.3333)\n",
      " Starting fold 8 / 10 (acc: 0.0667)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2667)\n",
      "Mean accuracy on test set: 0.2133\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.1333)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2667)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2667)\n",
      " Starting fold 9 / 10 (acc: 0.1333)\n",
      " Starting fold 10 / 10 (acc: 0.2667)\n",
      "Mean accuracy on test set: 0.2000\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2667)\n",
      " Starting fold 2 / 10 (acc: 0.1333)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.1333)\n",
      " Starting fold 9 / 10 (acc: 0.1333)\n",
      " Starting fold 10 / 10 (acc: 0.2667)\n",
      "Mean accuracy on test set: 0.1933\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.1333)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2667)\n",
      " Starting fold 8 / 10 (acc: 0.1333)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2667)\n",
      "Mean accuracy on test set: 0.1867\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2667)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2667)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.1333)\n",
      " Starting fold 8 / 10 (acc: 0.2667)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.2067\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2667)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.1333)\n",
      " Starting fold 10 / 10 (acc: 0.1333)\n",
      "Mean accuracy on test set: 0.1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "random_forest_acc_crowd_likert = random_forest(X_2D,\n",
    "                                               y_likert_crowd,\n",
    "                                               likert_crowd_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined likert labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.1600)\n",
      " Starting fold 3 / 10 (acc: 0.2400)\n",
      " Starting fold 4 / 10 (acc: 0.1200)\n",
      " Starting fold 5 / 10 (acc: 0.2400)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.0800)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1840\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.1600)\n",
      " Starting fold 2 / 10 (acc: 0.1200)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2400)\n",
      " Starting fold 5 / 10 (acc: 0.2400)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.1600)\n",
      " Starting fold 8 / 10 (acc: 0.1200)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1840\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.1600)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.1600)\n",
      " Starting fold 9 / 10 (acc: 0.1600)\n",
      " Starting fold 10 / 10 (acc: 0.1600)\n",
      "Mean accuracy on test set: 0.1840\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.1600)\n",
      " Starting fold 3 / 10 (acc: 0.1600)\n",
      " Starting fold 4 / 10 (acc: 0.1600)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.1200)\n",
      " Starting fold 7 / 10 (acc: 0.1600)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.1600)\n",
      " Starting fold 10 / 10 (acc: 0.1200)\n",
      "Mean accuracy on test set: 0.1640\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.1600)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.1600)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2400)\n",
      " Starting fold 8 / 10 (acc: 0.1600)\n",
      " Starting fold 9 / 10 (acc: 0.1600)\n",
      " Starting fold 10 / 10 (acc: 0.1600)\n",
      "Mean accuracy on test set: 0.1840\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.1600)\n",
      " Starting fold 3 / 10 (acc: 0.1600)\n",
      " Starting fold 4 / 10 (acc: 0.1600)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.1600)\n",
      " Starting fold 8 / 10 (acc: 0.1600)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.1600)\n",
      "Mean accuracy on test set: 0.1760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "random_forest_acc_combined_likert = random_forest(X_2D,\n",
    "                                                  y_likert_combined,\n",
    "                                                  likert_combined_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.6154)\n",
      " Starting fold 2 / 10 (acc: 0.5385)\n",
      " Starting fold 3 / 10 (acc: 0.7692)\n",
      " Starting fold 4 / 10 (acc: 0.5385)\n",
      " Starting fold 5 / 10 (acc: 0.7692)\n",
      " Starting fold 6 / 10 (acc: 0.6154)\n",
      " Starting fold 7 / 10 (acc: 0.5385)\n",
      " Starting fold 8 / 10 (acc: 0.5385)\n",
      " Starting fold 9 / 10 (acc: 0.5385)\n",
      " Starting fold 10 / 10 (acc: 0.6154)\n",
      "Mean accuracy on test set: 0.6077\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5385)\n",
      " Starting fold 2 / 10 (acc: 0.6923)\n",
      " Starting fold 3 / 10 (acc: 0.6154)\n",
      " Starting fold 4 / 10 (acc: 0.5385)\n",
      " Starting fold 5 / 10 (acc: 0.6923)\n",
      " Starting fold 6 / 10 (acc: 0.6923)\n",
      " Starting fold 7 / 10 (acc: 0.4615)\n",
      " Starting fold 8 / 10 (acc: 0.6154)\n",
      " Starting fold 9 / 10 (acc: 0.5385)\n",
      " Starting fold 10 / 10 (acc: 0.6154)\n",
      "Mean accuracy on test set: 0.6000\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.6154)\n",
      " Starting fold 2 / 10 (acc: 0.6154)\n",
      " Starting fold 3 / 10 (acc: 0.5385)\n",
      " Starting fold 4 / 10 (acc: 0.6154)\n",
      " Starting fold 5 / 10 (acc: 0.5385)\n",
      " Starting fold 6 / 10 (acc: 0.5385)\n",
      " Starting fold 7 / 10 (acc: 0.6923)\n",
      " Starting fold 8 / 10 (acc: 0.6923)\n",
      " Starting fold 9 / 10 (acc: 0.6154)\n",
      " Starting fold 10 / 10 (acc: 0.6154)\n",
      "Mean accuracy on test set: 0.6077\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.6923)\n",
      " Starting fold 2 / 10 (acc: 0.5385)\n",
      " Starting fold 3 / 10 (acc: 0.6923)\n",
      " Starting fold 4 / 10 (acc: 0.5385)\n",
      " Starting fold 5 / 10 (acc: 0.6154)\n",
      " Starting fold 6 / 10 (acc: 0.6154)\n",
      " Starting fold 7 / 10 (acc: 0.6923)\n",
      " Starting fold 8 / 10 (acc: 0.6154)\n",
      " Starting fold 9 / 10 (acc: 0.6923)\n",
      " Starting fold 10 / 10 (acc: 0.6154)\n",
      "Mean accuracy on test set: 0.6308\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.6154)\n",
      " Starting fold 2 / 10 (acc: 0.6154)\n",
      " Starting fold 3 / 10 (acc: 0.6154)\n",
      " Starting fold 4 / 10 (acc: 0.6154)\n",
      " Starting fold 5 / 10 (acc: 0.6154)\n",
      " Starting fold 6 / 10 (acc: 0.6923)\n",
      " Starting fold 7 / 10 (acc: 0.6923)\n",
      " Starting fold 8 / 10 (acc: 0.6923)\n",
      " Starting fold 9 / 10 (acc: 0.5385)\n",
      " Starting fold 10 / 10 (acc: 0.5385)\n",
      "Mean accuracy on test set: 0.6231\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.6923)\n",
      " Starting fold 2 / 10 (acc: 0.6154)\n",
      " Starting fold 3 / 10 (acc: 0.6154)\n",
      " Starting fold 4 / 10 (acc: 0.6923)\n",
      " Starting fold 5 / 10 (acc: 0.6923)\n",
      " Starting fold 6 / 10 (acc: 0.6154)\n",
      " Starting fold 7 / 10 (acc: 0.6923)\n",
      " Starting fold 8 / 10 (acc: 0.6154)\n",
      " Starting fold 9 / 10 (acc: 0.6154)\n",
      " Starting fold 10 / 10 (acc: 0.6923)\n",
      "Mean accuracy on test set: 0.6538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "random_forest_acc_experts_dominant = random_forest(X_2D,\n",
    "                                                   y_dominant_experts, \n",
    "                                                   dominant_expert_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on crowd dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.4167)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.5000)\n",
      " Starting fold 5 / 10 (acc: 0.5833)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5000)\n",
      " Starting fold 10 / 10 (acc: 0.4167)\n",
      "Mean accuracy on test set: 0.4917\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5000)\n",
      " Starting fold 2 / 10 (acc: 0.4167)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.5000)\n",
      " Starting fold 5 / 10 (acc: 0.5000)\n",
      " Starting fold 6 / 10 (acc: 0.4167)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.4167)\n",
      " Starting fold 9 / 10 (acc: 0.4167)\n",
      " Starting fold 10 / 10 (acc: 0.4167)\n",
      "Mean accuracy on test set: 0.4583\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5000)\n",
      " Starting fold 2 / 10 (acc: 0.4167)\n",
      " Starting fold 3 / 10 (acc: 0.4167)\n",
      " Starting fold 4 / 10 (acc: 0.5000)\n",
      " Starting fold 5 / 10 (acc: 0.4167)\n",
      " Starting fold 6 / 10 (acc: 0.5833)\n",
      " Starting fold 7 / 10 (acc: 0.4167)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.4167)\n",
      " Starting fold 10 / 10 (acc: 0.4167)\n",
      "Mean accuracy on test set: 0.4583\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.4167)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.4167)\n",
      " Starting fold 4 / 10 (acc: 0.4167)\n",
      " Starting fold 5 / 10 (acc: 0.5000)\n",
      " Starting fold 6 / 10 (acc: 0.4167)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.4167)\n",
      " Starting fold 10 / 10 (acc: 0.4167)\n",
      "Mean accuracy on test set: 0.4500\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.4167)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.4167)\n",
      " Starting fold 4 / 10 (acc: 0.4167)\n",
      " Starting fold 5 / 10 (acc: 0.4167)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.4167)\n",
      " Starting fold 8 / 10 (acc: 0.4167)\n",
      " Starting fold 9 / 10 (acc: 0.4167)\n",
      " Starting fold 10 / 10 (acc: 0.4167)\n",
      "Mean accuracy on test set: 0.4333\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.4167)\n",
      " Starting fold 2 / 10 (acc: 0.4167)\n",
      " Starting fold 3 / 10 (acc: 0.4167)\n",
      " Starting fold 4 / 10 (acc: 0.4167)\n",
      " Starting fold 5 / 10 (acc: 0.4167)\n",
      " Starting fold 6 / 10 (acc: 0.4167)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.4167)\n",
      " Starting fold 9 / 10 (acc: 0.4167)\n",
      " Starting fold 10 / 10 (acc: 0.5000)\n",
      "Mean accuracy on test set: 0.4333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "random_forest_acc_crowd_dominant = random_forest(X_2D,\n",
    "                                                 y_dominant_crowd,\n",
    "                                                 dominant_crowd_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on combined dominant labels ===\n",
      "Training with 100 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.5417)\n",
      " Starting fold 3 / 10 (acc: 0.5833)\n",
      " Starting fold 4 / 10 (acc: 0.5417)\n",
      " Starting fold 5 / 10 (acc: 0.5417)\n",
      " Starting fold 6 / 10 (acc: 0.5417)\n",
      " Starting fold 7 / 10 (acc: 0.5417)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5417)\n",
      " Starting fold 10 / 10 (acc: 0.6250)\n",
      "Mean accuracy on test set: 0.5500\n",
      "\n",
      "Training with 250 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.5417)\n",
      " Starting fold 4 / 10 (acc: 0.5833)\n",
      " Starting fold 5 / 10 (acc: 0.5417)\n",
      " Starting fold 6 / 10 (acc: 0.5417)\n",
      " Starting fold 7 / 10 (acc: 0.5417)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5417)\n",
      " Starting fold 10 / 10 (acc: 0.5417)\n",
      "Mean accuracy on test set: 0.5375\n",
      "\n",
      "Training with 500 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.5417)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.5417)\n",
      " Starting fold 5 / 10 (acc: 0.4583)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.5833)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5000)\n",
      " Starting fold 10 / 10 (acc: 0.6250)\n",
      "Mean accuracy on test set: 0.5292\n",
      "\n",
      "Training with 750 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5000)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.5417)\n",
      " Starting fold 4 / 10 (acc: 0.5000)\n",
      " Starting fold 5 / 10 (acc: 0.5417)\n",
      " Starting fold 6 / 10 (acc: 0.5417)\n",
      " Starting fold 7 / 10 (acc: 0.4583)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5000)\n",
      " Starting fold 10 / 10 (acc: 0.5000)\n",
      "Mean accuracy on test set: 0.5083\n",
      "\n",
      "Training with 1000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.5417)\n",
      " Starting fold 3 / 10 (acc: 0.4583)\n",
      " Starting fold 4 / 10 (acc: 0.5417)\n",
      " Starting fold 5 / 10 (acc: 0.5417)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5417)\n",
      " Starting fold 9 / 10 (acc: 0.5417)\n",
      " Starting fold 10 / 10 (acc: 0.5417)\n",
      "Mean accuracy on test set: 0.5250\n",
      "\n",
      "Training with 2000 estimators\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.5417)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.5417)\n",
      " Starting fold 5 / 10 (acc: 0.5417)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5417)\n",
      " Starting fold 10 / 10 (acc: 0.5417)\n",
      "Mean accuracy on test set: 0.5250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "random_forest_acc_combined_dominant = random_forest(X_2D,\n",
    "                                                    y_dominant_combined,\n",
    "                                                    dominant_combined_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "def pac(X, y, index, model=None, partial=False):\n",
    "    n_samples = X[index].shape[0]\n",
    "    acc = 0.0\n",
    "    best_score = -1\n",
    "    best_model = None\n",
    "    for fold_i in range(N_FOLDS):\n",
    "        print(\" Starting fold {} / {}\".format(fold_i+1, N_FOLDS), end='')\n",
    "\n",
    "        train_fold_idx, test_fold_idx  = create_splits(y[index])\n",
    "        train_idx = index[train_fold_idx]\n",
    "        test_idx = index[test_fold_idx]\n",
    "\n",
    "        if model is None:\n",
    "            if partial:\n",
    "                classes = np.unique(y)\n",
    "                model = PassiveAggressiveClassifier(max_iter=2000, warm_start=True)\n",
    "                model.partial_fit(X[train_idx], y[train_idx], classes)\n",
    "            else:\n",
    "                model = PassiveAggressiveClassifier(max_iter=2000, warm_start=False)\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "        else:\n",
    "            model.partial_fit(X[train_idx], y[train_idx])\n",
    "\n",
    "        y_pred = model.predict(X[test_idx])\n",
    "        fold_acc = accuracy_score(y[test_idx], y_pred)\n",
    "        \n",
    "        if best_score < 0 or best_score < (fold_acc - 0.02):\n",
    "            best_score = fold_acc\n",
    "            best_model = model\n",
    "        \n",
    "        if not partial:\n",
    "            model = None\n",
    "\n",
    "        acc += fold_acc\n",
    "        print(\" (acc: {:.4f})\".format(fold_acc))\n",
    "\n",
    "    acc /= N_FOLDS\n",
    "    print(\"Mean accuracy on test set: {:.4f}\\n\".format(acc))\n",
    "    \n",
    "    return (acc, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      " Starting fold 1 / 10 (acc: 0.2000)\n",
      " Starting fold 2 / 10 (acc: 0.2667)\n",
      " Starting fold 3 / 10 (acc: 0.2667)\n",
      " Starting fold 4 / 10 (acc: 0.2667)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2667)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.2667)\n",
      " Starting fold 10 / 10 (acc: 0.2667)\n",
      "Mean accuracy on test set: 0.2400\n",
      "\n",
      "=== Results of supervised learning on crowd likert labels ===\n",
      " Starting fold 1 / 10 (acc: 0.1333)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.2000)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2667)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.1333)\n",
      "Mean accuracy on test set: 0.1867\n",
      "\n",
      "=== Results of supervised learning on combined likert labels ===\n",
      " Starting fold 1 / 10 (acc: 0.2800)\n",
      " Starting fold 2 / 10 (acc: 0.1200)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.1600)\n",
      " Starting fold 6 / 10 (acc: 0.1600)\n",
      " Starting fold 7 / 10 (acc: 0.2400)\n",
      " Starting fold 8 / 10 (acc: 0.1200)\n",
      " Starting fold 9 / 10 (acc: 0.1600)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1840\n",
      "\n",
      "=== Results of supervised learning on expert dominant labels ===\n",
      " Starting fold 1 / 10 (acc: 0.6923)\n",
      " Starting fold 2 / 10 (acc: 0.6923)\n",
      " Starting fold 3 / 10 (acc: 0.7692)\n",
      " Starting fold 4 / 10 (acc: 0.6154)\n",
      " Starting fold 5 / 10 (acc: 0.6154)\n",
      " Starting fold 6 / 10 (acc: 0.6154)\n",
      " Starting fold 7 / 10 (acc: 0.6154)\n",
      " Starting fold 8 / 10 (acc: 0.6154)\n",
      " Starting fold 9 / 10 (acc: 0.7692)\n",
      " Starting fold 10 / 10 (acc: 0.6154)\n",
      "Mean accuracy on test set: 0.6615\n",
      "\n",
      "=== Results of supervised learning on crowd dominant labels ===\n",
      " Starting fold 1 / 10 (acc: 0.5000)\n",
      " Starting fold 2 / 10 (acc: 0.5000)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.4167)\n",
      " Starting fold 5 / 10 (acc: 0.4167)\n",
      " Starting fold 6 / 10 (acc: 0.4167)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5000)\n",
      " Starting fold 10 / 10 (acc: 0.5000)\n",
      "Mean accuracy on test set: 0.4750\n",
      "\n",
      "=== Results of supervised learning on combined dominant labels ===\n",
      " Starting fold 1 / 10 (acc: 0.5417)\n",
      " Starting fold 2 / 10 (acc: 0.4167)\n",
      " Starting fold 3 / 10 (acc: 0.5000)\n",
      " Starting fold 4 / 10 (acc: 0.5000)\n",
      " Starting fold 5 / 10 (acc: 0.5833)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.4167)\n",
      " Starting fold 8 / 10 (acc: 0.5833)\n",
      " Starting fold 9 / 10 (acc: 0.5417)\n",
      " Starting fold 10 / 10 (acc: 0.5000)\n",
      "Mean accuracy on test set: 0.5083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "pac_acc_experts_likert, _ = pac(X_2D,\n",
    "                                y_likert_experts, \n",
    "                                likert_expert_idx)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "pac_acc_crowd_likert, _ = pac(X_2D,\n",
    "                              y_likert_crowd,\n",
    "                              likert_crowd_idx)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined likert labels ===\")\n",
    "pac_acc_combined_likert, _ = pac(X_2D,\n",
    "                                 y_likert_combined,\n",
    "                                 likert_combined_idx)\n",
    "\n",
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "pac_acc_experts_dominant, _ = pac(X_2D,\n",
    "                                  y_dominant_experts, \n",
    "                                  dominant_expert_idx)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "pac_acc_crowd_dominant, _ = pac(X_2D,\n",
    "                                y_dominant_crowd,\n",
    "                                dominant_crowd_idx)\n",
    "\n",
    "print(\"=== Results of supervised learning on combined dominant labels ===\")\n",
    "pac_acc_combined_dominant, _ = pac(X_2D,\n",
    "                                   y_dominant_combined,\n",
    "                                   dominant_combined_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## incremental learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results of supervised learning on expert likert labels ===\n",
      " Starting fold 1 / 10 (acc: 0.0667)\n",
      " Starting fold 2 / 10 (acc: 0.2000)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.2000)\n",
      " Starting fold 5 / 10 (acc: 0.1333)\n",
      " Starting fold 6 / 10 (acc: 0.1333)\n",
      " Starting fold 7 / 10 (acc: 0.2000)\n",
      " Starting fold 8 / 10 (acc: 0.2000)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1733\n",
      "\n",
      "=== Results of supervised learning on crowd likert labels ===\n",
      " Starting fold 1 / 10 (acc: 0.2667)\n",
      " Starting fold 2 / 10 (acc: 0.2667)\n",
      " Starting fold 3 / 10 (acc: 0.2000)\n",
      " Starting fold 4 / 10 (acc: 0.1333)\n",
      " Starting fold 5 / 10 (acc: 0.2000)\n",
      " Starting fold 6 / 10 (acc: 0.0667)\n",
      " Starting fold 7 / 10 (acc: 0.1333)\n",
      " Starting fold 8 / 10 (acc: 0.2667)\n",
      " Starting fold 9 / 10 (acc: 0.2000)\n",
      " Starting fold 10 / 10 (acc: 0.2000)\n",
      "Mean accuracy on test set: 0.1933\n",
      "\n",
      "=== Results of supervised learning on expert dominant labels ===\n",
      " Starting fold 1 / 10 (acc: 0.7692)\n",
      " Starting fold 2 / 10 (acc: 0.6923)\n",
      " Starting fold 3 / 10 (acc: 0.6154)\n",
      " Starting fold 4 / 10 (acc: 0.6923)\n",
      " Starting fold 5 / 10 (acc: 0.6154)\n",
      " Starting fold 6 / 10 (acc: 0.6923)\n",
      " Starting fold 7 / 10 (acc: 0.6923)\n",
      " Starting fold 8 / 10 (acc: 0.6923)\n",
      " Starting fold 9 / 10 (acc: 0.6923)\n",
      " Starting fold 10 / 10 (acc: 0.7692)\n",
      "Mean accuracy on test set: 0.6923\n",
      "\n",
      "=== Results of supervised learning on crowd dominant labels ===\n",
      " Starting fold 1 / 10 (acc: 0.2500)\n",
      " Starting fold 2 / 10 (acc: 0.4167)\n",
      " Starting fold 3 / 10 (acc: 0.5833)\n",
      " Starting fold 4 / 10 (acc: 0.5833)\n",
      " Starting fold 5 / 10 (acc: 0.5833)\n",
      " Starting fold 6 / 10 (acc: 0.5000)\n",
      " Starting fold 7 / 10 (acc: 0.5000)\n",
      " Starting fold 8 / 10 (acc: 0.5000)\n",
      " Starting fold 9 / 10 (acc: 0.5000)\n",
      " Starting fold 10 / 10 (acc: 0.5000)\n",
      "Mean accuracy on test set: 0.4917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Results of supervised learning on expert likert labels ===\")\n",
    "pac_acc_experts_likert, model = pac(X_2D,\n",
    "                                    y_likert_experts, \n",
    "                                    likert_expert_idx,\n",
    "                                    partial=True)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd likert labels ===\")\n",
    "pac_acc_crowd_likert, _ = pac(X_2D,\n",
    "                              y_likert_crowd,\n",
    "                              likert_crowd_idx,\n",
    "                              model=model,\n",
    "                              partial=True)\n",
    "\n",
    "print(\"=== Results of supervised learning on expert dominant labels ===\")\n",
    "pac_acc_experts_dominant, model = pac(X_2D,\n",
    "                                      y_dominant_experts, \n",
    "                                      dominant_expert_idx,\n",
    "                                      partial=True)\n",
    "\n",
    "print(\"=== Results of supervised learning on crowd dominant labels ===\")\n",
    "pac_acc_crowd_dominant, _ = pac(X_2D,\n",
    "                                y_dominant_crowd,\n",
    "                                dominant_crowd_idx,\n",
    "                                model=model,\n",
    "                                partial=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert numpy arrays to PyTorch tensors\n",
    "X_2D = torch.from_numpy(X_2D)\n",
    "X_3D = torch.from_numpy(X_3D)\n",
    "y_likert_crowd = torch.from_numpy(y_likert_crowd)\n",
    "y_likert_experts = torch.from_numpy(y_likert_experts)\n",
    "y_likert_combined = torch.from_numpy(y_likert_combined)\n",
    "y_dominant_crowd = torch.from_numpy(y_dominant_crowd)\n",
    "y_dominant_experts = torch.from_numpy(y_dominant_experts)\n",
    "y_dominant_combined = torch.from_numpy(y_dominant_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(y_hat, y):\n",
    "    # y := 1D array of class labels\n",
    "    # y_hat := 2D array of one-hot class labels\n",
    "    _, labels = y_hat.max(dim=1)\n",
    "    return torch.mean(torch.eq(labels, y).float())\n",
    "\n",
    "def fit(model, X, y, index, lr=0.01, l2norm=0.01, n_folds=10, n_epoch=250, patience=-1, state=None, finetune=False):\n",
    "    n_samples = X[index].shape[0]\n",
    "\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    best_state = None\n",
    "    best_state_opt = None\n",
    "    best_score = -1\n",
    "    for fold_i in range(n_folds):\n",
    "        print(\"Starting fold {} / {}\".format(fold_i+1, n_folds), end='')\n",
    "        if state is None:\n",
    "            model.init()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "        else:\n",
    "            model.load_state_dict(state[0])\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2norm)\n",
    "            optimizer.load_state_dict(state[1])\n",
    "            if finetune:\n",
    "                for layer in model.layers[:-1]:\n",
    "                    layer.requires_grad = False\n",
    "            \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # early stopping\n",
    "        patience_left = patience\n",
    "        best_fold_score = -1\n",
    "        delta = 1e-4\n",
    "        best_fold_state = None\n",
    "        best_fold_state_opt = None\n",
    "        \n",
    "        train_fold_idx, test_fold_idx  = create_splits(y[index])\n",
    "        train_idx = index[train_fold_idx]\n",
    "        test_idx = index[test_fold_idx]\n",
    "        for epoch in range(n_epoch):\n",
    "            model.train()\n",
    "            \n",
    "            y_hat = model(X[train_idx].float())\n",
    "            train_acc = categorical_accuracy(y_hat, y[train_idx])\n",
    "            train_loss = criterion(y_hat, y[train_idx].long())\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            test_loss = None\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(X[test_idx].float())\n",
    "                test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "                test_loss = criterion(y_hat, y[test_idx].long())\n",
    "                \n",
    "            train_loss = float(train_loss.item())\n",
    "            test_loss = float(test_loss.item())\n",
    "\n",
    "            if best_fold_score < 0:\n",
    "                best_fold_score = test_loss\n",
    "                best_fold_state = model.state_dict()\n",
    "                best_fold_state_opt = optimizer.state_dict()\n",
    "                            \n",
    "            if patience <= 0:\n",
    "                continue\n",
    "            if test_loss >= best_fold_score - delta:\n",
    "                patience_left -= 1\n",
    "            else:\n",
    "                best_fold_score = test_loss\n",
    "                best_fold_state = model.state_dict()\n",
    "                best_fold_state_opt = optimizer.state_dict()\n",
    "                patience_left = patience\n",
    "            if patience_left <= 0:\n",
    "                model.load_state_dict(best_fold_state)\n",
    "                optimizer.load_state_dict(best_fold_state_opt)\n",
    "                break\n",
    "                \n",
    "        test_idx = index[create_splits(y[index])[1]]  # get new random test set to validate on\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(X[test_idx].float())\n",
    "            test_acc = categorical_accuracy(y_hat, y[test_idx])\n",
    "            test_loss = float(criterion(y_hat, y[test_idx].long()).item())\n",
    "        \n",
    "        loss += test_loss\n",
    "        acc += test_acc\n",
    "        if best_score < 0 or best_score > test_loss:\n",
    "            best_state = best_fold_state\n",
    "            best_state_opt = best_fold_state_opt\n",
    "            best_score = test_loss\n",
    "        print(\" - training accuracy: {:.4f} / loss: {:.4f} - test accuracy: {:.4f} / loss: {:.4f}\".format(train_acc,\n",
    "                                                                                          train_loss,\n",
    "                                                                                          test_acc,\n",
    "                                                                                          test_loss))\n",
    "        \n",
    "    loss /= n_folds\n",
    "    acc /= n_folds\n",
    "    print(\"average loss on test set: {:.4f}\".format(loss))\n",
    "    print(\"average accuracy on test set: {:.4f}\".format(acc))\n",
    "    \n",
    "    return (acc, (best_state, best_state_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNN(nn.Module):\n",
    "    \"\"\"Simple Neural Network Classifier\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, p_dropout=0.05):\n",
    "        super().__init__()\n",
    "        hidden_dim = (input_dim-output_dim)//2\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(input_dim, hidden_dim),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout(p=p_dropout)))\n",
    "            \n",
    "        self.layers.append(nn.Sequential(\n",
    "                            nn.Linear(hidden_dim, output_dim),\n",
    "                            nn.ReLU(inplace=True)))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)                          \n",
    "                           \n",
    "        return self.softmax(X)\n",
    "        \n",
    "    def init(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert likert labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.7674 / loss: 1.4071 - test accuracy: 0.0667 / loss: 2.0207\n",
      "Starting fold 2 / 10 - training accuracy: 0.7674 / loss: 1.4001 - test accuracy: 0.2000 / loss: 1.9427\n",
      "Starting fold 3 / 10 - training accuracy: 0.6744 / loss: 1.4972 - test accuracy: 0.2000 / loss: 1.9812\n",
      "Starting fold 4 / 10 - training accuracy: 0.8140 / loss: 1.3898 - test accuracy: 0.1333 / loss: 1.9958\n",
      "Starting fold 5 / 10 - training accuracy: 0.7907 / loss: 1.3893 - test accuracy: 0.1333 / loss: 2.0249\n",
      "Starting fold 6 / 10 - training accuracy: 0.6279 / loss: 1.5661 - test accuracy: 0.0667 / loss: 1.9870\n",
      "Starting fold 7 / 10 - training accuracy: 0.5814 / loss: 1.5876 - test accuracy: 0.1333 / loss: 2.0118\n",
      "Starting fold 8 / 10 - training accuracy: 0.5814 / loss: 1.5684 - test accuracy: 0.1333 / loss: 1.9880\n",
      "Starting fold 9 / 10 - training accuracy: 0.7442 / loss: 1.4364 - test accuracy: 0.0667 / loss: 2.0205\n",
      "Starting fold 10 / 10 - training accuracy: 0.6512 / loss: 1.5051 - test accuracy: 0.2000 / loss: 1.9290\n",
      "average loss on test set: 1.9902\n",
      "average accuracy on test set: 0.1333\n",
      "\n",
      "=== Results on crowd likert labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.7391 / loss: 1.4453 - test accuracy: 0.0667 / loss: 2.0202\n",
      "Starting fold 2 / 10 - training accuracy: 0.6739 / loss: 1.4742 - test accuracy: 0.2000 / loss: 1.9495\n",
      "Starting fold 3 / 10 - training accuracy: 0.6087 / loss: 1.5559 - test accuracy: 0.2000 / loss: 1.9276\n",
      "Starting fold 4 / 10 - training accuracy: 0.6522 / loss: 1.5134 - test accuracy: 0.2000 / loss: 1.9274\n",
      "Starting fold 5 / 10 - training accuracy: 0.8478 / loss: 1.3287 - test accuracy: 0.0667 / loss: 2.0694\n",
      "Starting fold 6 / 10 - training accuracy: 0.7826 / loss: 1.3828 - test accuracy: 0.2000 / loss: 1.9482\n",
      "Starting fold 7 / 10 - training accuracy: 0.6304 / loss: 1.5292 - test accuracy: 0.1333 / loss: 1.9791\n",
      "Starting fold 8 / 10 - training accuracy: 0.8261 / loss: 1.3846 - test accuracy: 0.1333 / loss: 1.9957\n",
      "Starting fold 9 / 10 - training accuracy: 0.6739 / loss: 1.5415 - test accuracy: 0.4667 / loss: 1.8041\n",
      "Starting fold 10 / 10 - training accuracy: 0.5435 / loss: 1.5710 - test accuracy: 0.1333 / loss: 1.9481\n",
      "average loss on test set: 1.9569\n",
      "average accuracy on test set: 0.1800\n",
      "\n",
      "=== Results on combined likert labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.6277 / loss: 1.5609 - test accuracy: 0.2000 / loss: 1.8864\n",
      "Starting fold 2 / 10 - training accuracy: 0.6702 / loss: 1.5377 - test accuracy: 0.2000 / loss: 1.9512\n",
      "Starting fold 3 / 10 - training accuracy: 0.6170 / loss: 1.5697 - test accuracy: 0.1200 / loss: 1.9879\n",
      "Starting fold 4 / 10 - training accuracy: 0.6383 / loss: 1.5791 - test accuracy: 0.1600 / loss: 1.9614\n",
      "Starting fold 5 / 10 - training accuracy: 0.5532 / loss: 1.6337 - test accuracy: 0.2000 / loss: 1.9349\n",
      "Starting fold 6 / 10 - training accuracy: 0.6489 / loss: 1.5585 - test accuracy: 0.1600 / loss: 1.9567\n",
      "Starting fold 7 / 10 - training accuracy: 0.5745 / loss: 1.5943 - test accuracy: 0.1600 / loss: 1.9704\n",
      "Starting fold 8 / 10 - training accuracy: 0.6064 / loss: 1.5887 - test accuracy: 0.0800 / loss: 2.0169\n",
      "Starting fold 9 / 10 - training accuracy: 0.6277 / loss: 1.5584 - test accuracy: 0.1200 / loss: 1.9891\n",
      "Starting fold 10 / 10 - training accuracy: 0.5745 / loss: 1.6011 - test accuracy: 0.1200 / loss: 1.9530\n",
      "average loss on test set: 1.9608\n",
      "average accuracy on test set: 0.1520\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_2D.shape[1]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert likert labels ===\")\n",
    "neural_net_acc_likert_experts, _ = fit(model, X_2D, y_likert_experts, likert_expert_idx, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd likert labels ===\")\n",
    "neural_net_acc_likert_crowd, _ = fit(model, X_2D, y_likert_crowd, likert_crowd_idx, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined likert labels ===\")\n",
    "neural_net_acc_likert_combined, _ = fit(model, X_2D, y_likert_combined, likert_combined_idx, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.9556 / loss: 0.3973 - test accuracy: 0.8462 / loss: 0.4506\n",
      "Starting fold 2 / 10 - training accuracy: 0.9333 / loss: 0.3892 - test accuracy: 0.7692 / loss: 0.5870\n",
      "Starting fold 3 / 10 - training accuracy: 0.9556 / loss: 0.3857 - test accuracy: 0.8462 / loss: 0.5572\n",
      "Starting fold 4 / 10 - training accuracy: 0.9778 / loss: 0.3470 - test accuracy: 0.6154 / loss: 0.6621\n",
      "Starting fold 5 / 10 - training accuracy: 0.9111 / loss: 0.3962 - test accuracy: 0.5385 / loss: 0.7243\n",
      "Starting fold 6 / 10 - training accuracy: 0.8444 / loss: 0.4604 - test accuracy: 0.6923 / loss: 0.5984\n",
      "Starting fold 7 / 10 - training accuracy: 0.9333 / loss: 0.3578 - test accuracy: 0.6923 / loss: 0.6164\n",
      "Starting fold 8 / 10 - training accuracy: 0.9556 / loss: 0.3762 - test accuracy: 0.6923 / loss: 0.6478\n",
      "Starting fold 9 / 10 - training accuracy: 0.9333 / loss: 0.3945 - test accuracy: 0.6923 / loss: 0.6261\n",
      "Starting fold 10 / 10 - training accuracy: 0.9556 / loss: 0.3698 - test accuracy: 0.6923 / loss: 0.6400\n",
      "average loss on test set: 0.6110\n",
      "average accuracy on test set: 0.7077\n",
      "\n",
      "=== Results on crowd dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.9545 / loss: 0.3827 - test accuracy: 0.5833 / loss: 0.6942\n",
      "Starting fold 2 / 10 - training accuracy: 0.8864 / loss: 0.4208 - test accuracy: 0.5833 / loss: 0.7368\n",
      "Starting fold 3 / 10 - training accuracy: 0.8864 / loss: 0.4245 - test accuracy: 0.4167 / loss: 0.8666\n",
      "Starting fold 4 / 10 - training accuracy: 0.9773 / loss: 0.3566 - test accuracy: 0.5000 / loss: 0.7433\n",
      "Starting fold 5 / 10 - training accuracy: 0.9091 / loss: 0.3768 - test accuracy: 0.5000 / loss: 0.7486\n",
      "Starting fold 6 / 10 - training accuracy: 0.9545 / loss: 0.3872 - test accuracy: 0.2500 / loss: 0.9291\n",
      "Starting fold 7 / 10 - training accuracy: 0.9545 / loss: 0.3766 - test accuracy: 0.4167 / loss: 0.7720\n",
      "Starting fold 8 / 10 - training accuracy: 0.8636 / loss: 0.4415 - test accuracy: 0.5000 / loss: 0.8164\n",
      "Starting fold 9 / 10 - training accuracy: 1.0000 / loss: 0.3479 - test accuracy: 0.4167 / loss: 0.7736\n",
      "Starting fold 10 / 10 - training accuracy: 0.9091 / loss: 0.3909 - test accuracy: 0.5000 / loss: 0.7766\n",
      "average loss on test set: 0.7857\n",
      "average accuracy on test set: 0.4667\n",
      "\n",
      "=== Results on combined dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.8444 / loss: 0.4726 - test accuracy: 0.5000 / loss: 0.7236\n",
      "Starting fold 2 / 10 - training accuracy: 0.8111 / loss: 0.4913 - test accuracy: 0.5000 / loss: 0.7206\n",
      "Starting fold 3 / 10 - training accuracy: 0.9111 / loss: 0.4130 - test accuracy: 0.5833 / loss: 0.6856\n",
      "Starting fold 4 / 10 - training accuracy: 0.8556 / loss: 0.4625 - test accuracy: 0.4583 / loss: 0.7933\n",
      "Starting fold 5 / 10 - training accuracy: 0.9333 / loss: 0.4104 - test accuracy: 0.4167 / loss: 0.7905\n",
      "Starting fold 6 / 10 - training accuracy: 0.9111 / loss: 0.4317 - test accuracy: 0.5833 / loss: 0.7056\n",
      "Starting fold 7 / 10 - training accuracy: 0.8889 / loss: 0.4384 - test accuracy: 0.5000 / loss: 0.6941\n",
      "Starting fold 8 / 10 - training accuracy: 0.8556 / loss: 0.4648 - test accuracy: 0.5417 / loss: 0.7125\n",
      "Starting fold 9 / 10 - training accuracy: 0.9111 / loss: 0.4286 - test accuracy: 0.4583 / loss: 0.7387\n",
      "Starting fold 10 / 10 - training accuracy: 0.8222 / loss: 0.4722 - test accuracy: 0.5000 / loss: 0.7568\n",
      "average loss on test set: 0.7321\n",
      "average accuracy on test set: 0.5042\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.1\n",
    "\n",
    "## define model\n",
    "indim = X_2D.shape[1]\n",
    "outdim = np.unique(y_dominant_experts[dominant_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_dominant_crowd[dominant_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "neural_net_acc_dominant_experts, _ = fit(model, X_2D, y_dominant_experts, dominant_expert_idx, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "neural_net_acc_dominant_crowd, _ = fit(model, X_2D, y_dominant_crowd, dominant_crowd_idx, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on combined dominant labels ===\")\n",
    "neural_net_acc_dominant_combined, _ = fit(model, X_2D, y_dominant_combined, dominant_combined_idx, lr=lr, n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.9556 / loss: 0.3715 - test accuracy: 0.6154 / loss: 0.5987\n",
      "Starting fold 2 / 10 - training accuracy: 0.7556 / loss: 0.4891 - test accuracy: 0.5385 / loss: 0.6435\n",
      "Starting fold 3 / 10 - training accuracy: 0.8889 / loss: 0.3993 - test accuracy: 0.6154 / loss: 0.6419\n",
      "Starting fold 4 / 10 - training accuracy: 0.9111 / loss: 0.4253 - test accuracy: 0.7692 / loss: 0.6000\n",
      "Starting fold 5 / 10 - training accuracy: 0.9556 / loss: 0.3809 - test accuracy: 0.8462 / loss: 0.5359\n",
      "Starting fold 6 / 10 - training accuracy: 0.8222 / loss: 0.4919 - test accuracy: 0.6154 / loss: 0.6430\n",
      "Starting fold 7 / 10 - training accuracy: 0.8889 / loss: 0.4282 - test accuracy: 0.6154 / loss: 0.5870\n",
      "Starting fold 8 / 10 - training accuracy: 0.8889 / loss: 0.3906 - test accuracy: 0.7692 / loss: 0.5811\n",
      "Starting fold 9 / 10 - training accuracy: 0.8889 / loss: 0.4242 - test accuracy: 0.6923 / loss: 0.5837\n",
      "Starting fold 10 / 10 - training accuracy: 0.7778 / loss: 0.5232 - test accuracy: 0.6923 / loss: 0.6308\n",
      "average loss on test set: 0.6046\n",
      "average accuracy on test set: 0.6769\n",
      "\n",
      "=== Results on crowd dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.9773 / loss: 0.3472 - test accuracy: 0.5000 / loss: 0.8100\n",
      "Starting fold 2 / 10 - training accuracy: 1.0000 / loss: 0.3298 - test accuracy: 0.5000 / loss: 0.7674\n",
      "Starting fold 3 / 10 - training accuracy: 1.0000 / loss: 0.3266 - test accuracy: 0.5000 / loss: 0.7431\n",
      "Starting fold 4 / 10 - training accuracy: 1.0000 / loss: 0.3340 - test accuracy: 0.5000 / loss: 0.7472\n",
      "Starting fold 5 / 10 - training accuracy: 1.0000 / loss: 0.3380 - test accuracy: 0.5000 / loss: 0.7472\n",
      "Starting fold 6 / 10 - training accuracy: 0.9773 / loss: 0.3480 - test accuracy: 0.4167 / loss: 0.7603\n",
      "Starting fold 7 / 10 - training accuracy: 0.9773 / loss: 0.3436 - test accuracy: 0.5000 / loss: 0.7641\n",
      "Starting fold 8 / 10 - training accuracy: 1.0000 / loss: 0.3365 - test accuracy: 0.5000 / loss: 0.7499\n",
      "Starting fold 9 / 10 - training accuracy: 1.0000 / loss: 0.3287 - test accuracy: 0.5000 / loss: 0.7408\n",
      "Starting fold 10 / 10 - training accuracy: 0.9773 / loss: 0.3397 - test accuracy: 0.5000 / loss: 0.7638\n",
      "average loss on test set: 0.7594\n",
      "average accuracy on test set: 0.4917\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "n_epoch = 250\n",
    "p_dropout = 0.1\n",
    "\n",
    "## define model\n",
    "indim = X_2D.shape[1]\n",
    "outdim = np.unique(y_dominant_experts[dominant_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_dominant_crowd[dominant_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierNN(input_dim=indim,\n",
    "                     output_dim=outdim,\n",
    "                     p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "neural_net_acc_dominant_experts, state = fit(model, X_2D, y_dominant_experts, dominant_expert_idx, lr=lr, n_epoch=n_epoch)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "neural_net_acc_dominant_crowd, _ = fit(model, X_2D, y_dominant_crowd, dominant_crowd_idx, lr=lr, n_epoch=n_epoch, state=state, finetune=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierCNN(nn.Module):\n",
    "    \"\"\"CNN Classifier\"\"\"\n",
    "\n",
    "    def __init__(self, features_in, features_out, p_dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(features_in, int(features_in*1.5), kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=3), \n",
    "\n",
    "            nn.Conv1d(int(features_in*1.5), int(features_in*2), kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv1d(int(features_in*2), int(features_in*2), kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveMaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(int(features_in*2)*2, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_dropout),\n",
    "\n",
    "            nn.Linear(32, features_out)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.conv(X)\n",
    "        X = X.view(X.size(0), -1)\n",
    "\n",
    "        return self.softmax(self.fc(X))\n",
    "        \n",
    "    def init(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert likert labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.1837 / loss: 1.9817 - test accuracy: 0.1111 / loss: 2.0543\n",
      "Starting fold 2 / 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c39012e17b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Results on expert likert labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcnn_acc_likert_experts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_likert_experts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikert_expert_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Results on crowd likert labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-56ca24edf86b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, X, y, index, lr, l2norm, n_folds, n_epoch, patience, state)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_3D.shape[2]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierCNN(features_in=indim,\n",
    "                      features_out=outdim,\n",
    "                      p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert likert labels ===\")\n",
    "cnn_acc_likert_experts = fit(model, X_3D.transpose(1, 2), y_likert_experts, likert_expert_idx, lr=lr)\n",
    "\n",
    "print(\"\\n=== Results on crowd likert labels ===\")\n",
    "cnn_acc_likert_crowd = fit(model, X_3D.transpose(1, 2), y_likert_crowd, likert_crowd_idx, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert dominant labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.0000 / loss: 2.1654 - test accuracy: 0.0000 / loss: 2.1654\n",
      "Starting fold 2 / 10 - training accuracy: 0.7368 / loss: 1.4286 - test accuracy: 0.6667 / loss: 1.4988\n",
      "Starting fold 3 / 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b335496dca96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Results on expert dominant labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcnn_acc_dominant_experts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dominant_experts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdominant_expert_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Results on crowd dominant labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-56ca24edf86b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, X, y, index, lr, l2norm, n_folds, n_epoch, patience, state)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b14099690259>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    199\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 201\u001b[0;31m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    202\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_3D.shape[2]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierCNN(features_in=indim,\n",
    "                      features_out=outdim,\n",
    "                      p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "cnn_acc_dominant_experts = fit(model, X_3D.transpose(1, 2), y_dominant_experts, dominant_expert_idx, lr=lr)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "cnn_acc_dominant_crowd = fit(model, X_3D.transpose(1, 2), y_dominant_crowd, dominant_crowd_idx, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 output_dim,\n",
    "                 hidden_dim,\n",
    "                 num_layers=1,\n",
    "                 p_dropout=0.0):\n",
    "        \"\"\"\n",
    "        LSTM\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            bias=True,\n",
    "                            batch_first=True)  # (batch, seq, feature)\n",
    "                            \n",
    "        fc_hidden_dim = (hidden_dim-output_dim)//2\n",
    "        self.fc = nn.Sequential(nn.Linear(hidden_dim, fc_hidden_dim),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Dropout(p=p_dropout),\n",
    "                                \n",
    "                                nn.Linear(fc_hidden_dim, output_dim))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # default H0 is zero vector\n",
    "        # output Hn is representation of entire sequence\n",
    "        X, _ = self.lstm(X)\n",
    "        X = X[:,-1,:]  # only consider final output\n",
    "\n",
    "        return self.softmax(self.fc(X))\n",
    "\n",
    "    def init(self):\n",
    "        sqrt_k = sqrt(1.0/self.hidden_dim)\n",
    "        for param in self.parameters():\n",
    "            nn.init.uniform_(param, -sqrt_k, sqrt_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClassifierLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e63a6942786e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0moutdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_likert_crowd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlikert_crowd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = ClassifierLSTM(input_dim=indim,\n\u001b[0m\u001b[1;32m     11\u001b[0m                        \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                        \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ClassifierLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_3D.shape[2]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "\n",
    "model = ClassifierLSTM(input_dim=indim,\n",
    "                       output_dim=outdim,\n",
    "                       hidden_dim=indim,\n",
    "                       p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert dominant labels ===\")\n",
    "lstm_acc_dominant_experts = fit(model, X_3D, y_dominant_experts, dominant_expert_idx, lr=lr)\n",
    "\n",
    "print(\"\\n=== Results on crowd dominant labels ===\")\n",
    "lstm_acc_dominant_crowd = fit(model, X_3D, y_dominant_crowd, dominant_crowd_idx, lr=lr)\n",
    "\n",
    "print(\"=== Results on combined dominant labels ===\")\n",
    "lstm_acc_dominant_combined = fit(model, X_3D, y_dominant_combined, dominant_combined_idx, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results on expert likert labels ===\n",
      "Starting fold 1 / 10 - training accuracy: 0.2449 / loss: 1.9027 - test accuracy: 0.2222 / loss: 1.9174\n",
      "Starting fold 2 / 10 - training accuracy: 0.2449 / loss: 1.8814 - test accuracy: 0.2222 / loss: 1.9046\n",
      "Starting fold 3 / 10 - training accuracy: 0.2449 / loss: 1.8906 - test accuracy: 0.2222 / loss: 1.9030\n",
      "Starting fold 4 / 10 - training accuracy: 0.2449 / loss: 1.8934 - test accuracy: 0.2222 / loss: 1.9050\n",
      "Starting fold 5 / 10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-53c3ef29bc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Results on expert likert labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlstm_acc_likert_experts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_likert_experts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlikert_expert_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Results on crowd likert labels ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-56ca24edf86b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, X, y, index, lr, l2norm, n_folds, n_epoch, patience, state)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "lr = 0.01\n",
    "p_dropout = 0.05\n",
    "\n",
    "## define model\n",
    "indim = X_3D.shape[2]\n",
    "outdim = np.unique(y_likert_experts[likert_expert_idx]).shape[0]\n",
    "assert outdim == np.unique(y_likert_crowd[likert_crowd_idx]).shape[0]\n",
    "hidden_dim = (indim-outdim)//2\n",
    "\n",
    "model = ClassifierLSTM(input_dim=indim,\n",
    "                       output_dim=outdim,\n",
    "                       hidden_dim=hidden_dim,\n",
    "                       p_dropout=p_dropout)\n",
    "\n",
    "print(\"=== Results on expert likert labels ===\")\n",
    "lstm_acc_likert_experts = fit(model, X_3D, y_likert_experts, likert_expert_idx, lr=lr)\n",
    "\n",
    "print(\"\\n=== Results on crowd likert labels ===\")\n",
    "lstm_acc_likert_crowd = fit(model, X_3D, y_likert_crowd, likert_crowd_idx, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
